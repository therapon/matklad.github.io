<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
<link href="https://matklad.github.io/feed.xml" rel="self" type="application/atom+xml"/>
<link href="https://matklad.github.io" rel="alternate" type="text/html"/>
<updated>2024-07-25T20:38:19.605Z</updated>
<id>https://matklad.github.io/feed.xml</id>
<title type="html">matklad</title>
<subtitle>Yet another programming blog by Alex Kladov aka matklad.</subtitle>
<author><name>Alex Kladov</name></author>

<entry>
<title type="text">How I Use Git Worktrees</title>
<link href="https://matklad.github.io/2024/07/25/git-worktrees.html" rel="alternate" type="text/html" title="How I Use Git Worktrees" />
<published>2024-07-25T00:00:00+00:00</published>
<updated>2024-07-25T00:00:00+00:00</updated>
<id>https://matklad.github.io/2024/07/25/git-worktrees</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[There are a bunch of posts on the internet about using git worktree command. As far as I can tell,
most of them are primarily about using worktrees as a replacement of, or a supplement to git
branches. Instead of switching branches, you just change directories. This is also how I originally
had useed worktrees, but that didn't stick, and I abandoned them. But recently worktrees grew
on me, though my new use-case is unlike branching.]]></summary>
<content type="html" xml:base="https://matklad.github.io/2024/07/25/git-worktrees.html"><![CDATA[
<h1><span>How I Use Git Worktrees</span> <time class="meta" datetime="2024-07-25">Jul 25, 2024</time></h1>
<p><span>There are a bunch of posts on the internet about using </span><code>git worktree</code><span> command. As far as I can tell,</span>
<span>most of them are primarily about using worktrees as a replacement of, or a supplement to git</span>
<span>branches. Instead of switching branches, you just change directories. This is also how I originally</span>
<span>had useed worktrees, but that didn</span>&rsquo;<span>t stick, and I abandoned them. But recently worktrees grew</span>
<span>on me, though my new use-case is unlike branching.</span></p>
<section id="When-a-Branch-is-Enough">

    <h2>
    <a href="#When-a-Branch-is-Enough"><span>When a Branch is Enough</span> </a>
    </h2>
<p><span>If you use worktrees as a replacement for branching, that</span>&rsquo;<span>s great, no need to change anything! But</span>
<span>let me start with explaining why that workflow isn</span>&rsquo;<span>t for me.</span></p>
<p><span>The principle problem with using branches is that it</span>&rsquo;<span>s hard to context switch in the middle of doing</span>
<span>something. You have your branch, your commit, a bunch of changes in the work tree, some of them</span>
<span>might be stage and some upstage. You can</span>&rsquo;<span>t really tell Git </span>&ldquo;<span>save all this context and restore it</span>
<span>later</span>&rdquo;<span>. The solution that git suggests here is to use stashing, but that</span>&rsquo;<span>s awkward, as it is too</span>
<span>easy to get lost when stashing several things at the same time, and then applying the stash on top</span>
<span>of the wrong branch.</span></p>
<p><span>Managing git state became much easier for me when I realize that staging area and stash are just bad</span>
<span>features, and life</span>&rsquo;<span>s easier if I avoid them. Instead, I just commit whatever and deal with</span>
<span>it later. So, when I need to switch a branch in the middle of things, what I do is, basically:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-title function_">$</span> git add .</span>
<span class="line"><span class="hl-title function_">$</span> git commit -m.</span>
<span class="line"><span class="hl-title function_">$</span> git switch another-branch</span></code></pre>

</figure>
<p><span>And, to switch back,</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-title function_">$</span> git switch -</span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-comment"># Undo the last commit, but keep its changes in the working tree</span></span>
<span class="line"><span class="hl-title function_">$</span> git reset HEAD~</span></code></pre>

</figure>
<p><span>To make this more streamlined, I have a </span><code>ggc</code><span> utility which does </span>&ldquo;<span>commit all with a trivial message</span>&rdquo;
<span>atomically.</span></p>

<aside class="admn note">
<svg class="icon"><use href="/assets/icons.svg#info"/></svg>
<div><p><span>Reminder: git is not a version control system, git is a toolbox for building a VCS. Do have a</span>
<span>low-friction way to add your own scripts for common git operations.</span></p>
</div>
</aside><p><span>And I don</span>&rsquo;<span>t always </span><code>reset HEAD~</code><span> </span>&mdash;<span> I usually just continue hacking with </span><code>.</code><span> in my git log and then amend the commit</span>
<span>once I am satisfied with subset of changes</span></p>

<aside class="admn note">
<svg class="icon"><use href="/assets/icons.svg#info"/></svg>
<div><p><span>Reminder: magit, for </span><a href="https://magit.vc"><span>Emacs</span></a><span> and </span><a href="https://github.com/kahole/edamagit"><span>VS Code</span></a><span>, is</span>
<span>excellent for making such commit surgery easy. In particular, </span><strong><strong><span>instant fixup</span></strong></strong><span> is excellent. Even</span>
<span>if you don</span>&rsquo;<span>t use magit, you should have an equivalent of instant fixup among your git scripts.</span></p>
</div>
</aside><p><span>So that</span>&rsquo;<span>s how I deal with switching branches. But why worktrees then?</span></p>
</section>
<section id="Worktree-Per-Concurrent-Activity">

    <h2>
    <a href="#Worktree-Per-Concurrent-Activity"><span>Worktree Per Concurrent Activity</span> </a>
    </h2>
<p><span>It</span>&rsquo;<span>s a bit hard to describe, but:</span></p>
<ul>
<li>
<span>I have a fixed number of worktrees (5, to be exact)</span>
</li>
<li>
<span>worktrees are mostly uncorrelated to branches</span>
</li>
<li>
<span>and instead correspond to my concurrent activities during coding</span>
</li>
</ul>
<p><span>Specifically:</span></p>
<ul>
<li>
<p><span>The </span><strong><span>main</span></strong><span> worktree is a readonly worktree that contains a recent snapshot of the remote main</span>
<span>branch. I use this tree to compare the code I am currently working on and/or reviewing with the</span>
<span>master version (this includes things like </span>&ldquo;<span>how long the build takes</span>&rdquo;<span>, </span>&ldquo;<span>what is the behavior of</span>
<span>this test</span>&rdquo;<span> and the like, so not just the actual source code).</span></p>
</li>
<li>
<p><span>The </span><strong><span>work</span></strong><span> worktree, where I write most of the code. I often need to write new code and compare it</span>
<span>with old code at the same time. But can</span>&rsquo;<span>t actually work on two different things in parallel.</span>
<span>That</span>&rsquo;<span>s why </span><code>main</code><span> and </span><code>work</code><span> are different branches, but </span><code>work</code><span> also constantly switches branches.</span></p>
</li>
<li>
<p><span>The </span><strong><span>review</span></strong><span> worktree, where I checkout code for code review. While I can</span>&rsquo;<span>t review code and write</span>
<span>code at the same time, there is one thing I am implementing, and one thing I am reviewing, but the</span>
<span>review and implementation proceed concurrently.</span></p>
</li>
<li>
<p><span>Then, there</span>&rsquo;<span>s </span><strong><span>fuzz</span></strong><span> tree, where I run log-running fuzzing jobs for the code I am actively working</span>
<span>on. My overall idealized feature workflow looks like this:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-comment"># go to the `work` worktree</span></span>
<span class="line"><span class="hl-title function_">$</span> cd ~/projects/tigerbeetle/work</span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-comment"># Create a new branch. As we work with a centralized repo,</span></span>
<span class="line"><span class="hl-comment"># rather than personal forks, I tend to prefix my branch names</span></span>
<span class="line"><span class="hl-comment"># with `matklad/`</span></span>
<span class="line"><span class="hl-title function_">$</span> git switch -c matklad/awesome-feature</span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-comment"># Start with a reasonably clean slate.</span></span>
<span class="line"><span class="hl-comment"># In reality, I have yet another script to start a branch off</span></span>
<span class="line"><span class="hl-comment"># fresh remote main, but this reset is a good enough approximation.</span></span>
<span class="line"><span class="hl-title function_">$</span> git reset --hard origin/main</span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-comment"># For more complicated features, I start with an empty commit</span></span>
<span class="line"><span class="hl-comment"># and write the commit message _first_, before starting the work.</span></span>
<span class="line"><span class="hl-comment"># That's a good way to collect your thoughts and discover dead</span></span>
<span class="line"><span class="hl-comment"># ends more gracefully than hitting a brick wall coding at 80 WPM.</span></span>
<span class="line"><span class="hl-title function_">$</span> git commit --allow-empty</span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-comment"># Hack furiously writing throughway code.</span></span>
<span class="line"><span class="hl-title function_">$</span> code .</span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-comment"># At this point, I have something that I hope works,</span></span>
<span class="line"><span class="hl-comment"># but I would be embarrassed to share with anyone!</span></span>
<span class="line"><span class="hl-comment"># So that's the good place to kick off fuzzing.</span></span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-comment"># First, I commit everything so far.</span></span>
<span class="line"><span class="hl-comment"># Remember, I have `ggc` one liner for this:</span></span>
<span class="line"><span class="hl-title function_">$</span> git add . &amp;&amp; git commit -m.</span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-comment"># Now I go to my `fuzz` worktree and kick off fuzzing.</span></span>
<span class="line"><span class="hl-comment"># I usually split screen here.</span></span>
<span class="line"><span class="hl-comment"># On the left, I copy the current commit hash.</span></span>
<span class="line"><span class="hl-comment"># On the right, I switch to the fuzzing worktree,</span></span>
<span class="line"><span class="hl-comment"># switch to the copied commit, and start fuzzing:</span></span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-title function_">$</span> git add . &amp;&amp; git commit -m.  |</span>
<span class="line"><span class="hl-title function_">$</span> git rev-parse HEAD | ctrlc   | $ cd ../fuzz</span>
<span class="line"><span class="hl-title function_">$</span>                              | $ git switch -d $(ctrlv)</span>
<span class="line"><span class="hl-title function_">$</span>                              | $ ./zig/zig build fuzz</span>
<span class="line"><span class="hl-title function_">$</span>                              |</span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-comment"># While the fuzzer hums on right, I continue to furiously refactor</span></span>
<span class="line"><span class="hl-comment"># the code on the left and hammer my empty commit with a wishful</span></span>
<span class="line"><span class="hl-comment"># thinking message and my messy code commit with `.` message into</span></span>
<span class="line"><span class="hl-comment"># a semblance of clean git history</span></span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-title function_">$</span> code .</span>
<span class="line"><span class="hl-title function_">$</span> magit-goes-brrrrr</span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-comment"># At this point, in the work tree, I am happy with both the code</span></span>
<span class="line"><span class="hl-comment"># and the git history, so, if the fuzzer on the right is happy,</span></span>
<span class="line"><span class="hl-comment"># a PR is opened!</span></span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-title function_">$</span>                              |</span>
<span class="line"><span class="hl-title function_">$</span> git push --fore-with-lease   | $ ./zig/zig build fuzz</span>
<span class="line"><span class="hl-title function_">$</span> gh pr create --web           | # Still hasn't failed</span>
<span class="line"><span class="hl-title function_">$</span>                              |</span></code></pre>

</figure>
<p><span>This is again concurrency: I can hack on the branch while the fuzzer tests the </span>&ldquo;<span>same</span>&rdquo;<span> code. Note</span>
<span>that it is crucial that the fuzzing tree operates in the detached head state (</span><code>-d</code><span> flag for </span><code>git</code>
<code>switch</code><span>). In general, </span><code>-d</code><span> is very helpful with this style of worktree work. I am also</span>
<span>sympathetic to </span><a href="https://martinvonz.github.io/jj/latest/"><span>the argument</span></a><span> that, like the staging area</span>
<span>and the stash, git branches are a miss feature, but I haven</span>&rsquo;<span>t made the plunge personally yet.</span></p>
</li>
<li>
<p><span>Finally, the last tree I have is </span><strong><span>scratch</span></strong><span> </span>&mdash;<span> this is a tree for arbitrary random things I need</span>
<span>to do while working on something else. For example, if I am working on </span><code>matklad/my-feature</code><span> in</span>
<code>work</code><span>, and reviewing </span><code>#6292</code><span> in </span><code>review</code><span>, and, while reviewing, notice a tiny unrelated typo, the</span>
<span>PR for that typo is quickly prepped in the </span><code>scratch</code><span> worktree:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-title function_">$</span> cd ../scartch</span>
<span class="line"><span class="hl-title function_">$</span> git switch -c matklad/quick-fix</span>
<span class="line"><span class="hl-title function_">$</span> code . &amp;&amp; git add . &amp;&amp; git commit -m 'typo' &amp;&amp; git push</span>
<span class="line"><span class="hl-title function_">$</span> cd -</span></code></pre>

</figure>
</li>
</ul>
<p><span>TL;DR: consider using worktrees not as a replacement for branches, but as a means to manage</span>
<span>concurrency in your tasks. My level of concurrency is:</span></p>
<ul>
<li>
<code>main</code><span> for looking at the pristine code,</span>
</li>
<li>
<code>work</code><span> for looking at my code,</span>
</li>
<li>
<code>review</code><span> for looking at someone elses code,</span>
</li>
<li>
<code>fuzz</code><span> for my computer to look at my code,</span>
</li>
<li>
<code>scratch</code><span> for everything else!</span>
</li>
</ul>
</section>
]]></content>
</entry>

<entry>
<title type="text">Properly Testing Concurrent Data Structures</title>
<link href="https://matklad.github.io/2024/07/05/properly-testing-concurrent-data-structures.html" rel="alternate" type="text/html" title="Properly Testing Concurrent Data Structures" />
<published>2024-07-05T00:00:00+00:00</published>
<updated>2024-07-05T00:00:00+00:00</updated>
<id>https://matklad.github.io/2024/07/05/properly-testing-concurrent-data-structures</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[There's a fascinating Rust library, loom, which can be used to
thoroughly test lock-free data structures. I always wanted to learn how it works. I still do! But
recently I accidentally implemented a small toy which, I think, contains some of the loom's ideas,
and it seems worthwhile to write about that. The goal here isn't to teach you what you should be
using in practice (if you need that, go read loom's docs), but rather to derive a couple of neat
ideas from first principles.]]></summary>
<content type="html" xml:base="https://matklad.github.io/2024/07/05/properly-testing-concurrent-data-structures.html"><![CDATA[
<h1><span>Properly Testing Concurrent Data Structures</span> <time class="meta" datetime="2024-07-05">Jul 5, 2024</time></h1>
<p><span>There</span>&rsquo;<span>s a fascinating Rust library, </span><a href="https://github.com/tokio-rs/loom"><span>loom</span></a><span>, which can be used to</span>
<span>thoroughly test lock-free data structures. I always wanted to learn how it works. I still do! But</span>
<span>recently I accidentally implemented a small toy which, I think, contains some of the loom</span>&rsquo;<span>s ideas,</span>
<span>and it seems worthwhile to write about that. The goal here isn</span>&rsquo;<span>t to teach you what you should be</span>
<span>using in practice (if you need that, go read loom</span>&rsquo;<span>s docs), but rather to derive a couple of neat</span>
<span>ideas from first principles.</span></p>
<section id="One-Two-Three-Two">

    <h2>
    <a href="#One-Two-Three-Two"><span>One, Two, Three, Two</span> </a>
    </h2>
<p><span>As usual, we need the simplest possible model program to mess with. The example we use comes from</span>
<a href="https://stevana.github.io/the_sad_state_of_property-based_testing_libraries.html"><span>this excellent article</span></a><span>.</span>
<span>Behold, a humble (and broken) concurrent counter:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">use</span> std::sync::atomic::{</span>
<span class="line">  AtomicU32,</span>
<span class="line">  Ordering::SeqCst,</span>
<span class="line">};</span>
<span class="line"></span>
<span class="line"><span class="hl-meta">#[derive(Default)]</span></span>
<span class="line"><span class="hl-keyword">pub</span> <span class="hl-keyword">struct</span> <span class="hl-title class_">Counter</span> {</span>
<span class="line">  value: AtomicU32,</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">Counter</span> {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">increment</span>(&amp;<span class="hl-keyword">self</span>) {</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">value</span> = <span class="hl-keyword">self</span>.value.<span class="hl-title function_ invoke__">load</span>(SeqCst);</span>
<span class="line">    <span class="hl-keyword">self</span>.value.<span class="hl-title function_ invoke__">store</span>(value + <span class="hl-number">1</span>, SeqCst);</span>
<span class="line">  }</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">get</span>(&amp;<span class="hl-keyword">self</span>) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">u32</span> {</span>
<span class="line">    <span class="hl-keyword">self</span>.value.<span class="hl-title function_ invoke__">load</span>(SeqCst)</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>The bug is obvious here </span>&mdash;<span> the increment is not atomic. But what is the best test we can write to</span>
<span>expose it?</span></p>
</section>
<section id="Trivial-Test">

    <h2>
    <a href="#Trivial-Test"><span>Trivial Test</span> </a>
    </h2>
<p><span>The simplest idea that comes to mind is to just hammer the same counter from multiple threads and</span>
<span>check the result at the end;</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-meta">#[test]</span></span>
<span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">threaded_test</span>() {</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">counter</span> = Counter::<span class="hl-title function_ invoke__">default</span>();</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">thread_count</span> = <span class="hl-number">100</span>;</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">increment_count</span> = <span class="hl-number">100</span>;</span>
<span class="line"></span>
<span class="line">  std::thread::<span class="hl-title function_ invoke__">scope</span>(|scope| {</span>
<span class="line">    <span class="hl-keyword">for</span> <span class="hl-variable">_</span> <span class="hl-keyword">in</span> <span class="hl-number">0</span>..thread_count {</span>
<span class="line">      scope.<span class="hl-title function_ invoke__">spawn</span>(|| {</span>
<span class="line">        <span class="hl-keyword">for</span> <span class="hl-variable">_</span> <span class="hl-keyword">in</span> <span class="hl-number">0</span>..increment_count {</span>
<span class="line">          counter.<span class="hl-title function_ invoke__">increment</span>()</span>
<span class="line">        }</span>
<span class="line">      });</span>
<span class="line">    }</span>
<span class="line">  });</span>
<span class="line"></span>
<span class="line">  <span class="hl-built_in">assert_eq!</span>(counter.<span class="hl-title function_ invoke__">get</span>(), thread_count * increment_count);</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>This fails successfully:</span></p>

<figure class="code-block">


<pre><code><span class="line">thread 'counter::trivial' panicked:</span>
<span class="line">assertion `left == right` failed</span>
<span class="line">  left: 9598</span>
<span class="line"> right: 10000</span></code></pre>

</figure>
<p><span>But I wouldn</span>&rsquo;<span>t call this test satisfactory </span>&mdash;<span> it very much depends on the timing, so you can</span>&rsquo;<span>t</span>
<span>reproduce it deterministically and you can</span>&rsquo;<span>t debug it. You also can</span>&rsquo;<span>t minimize it </span>&mdash;<span> if you reduce</span>
<span>the number of threads and increments, chances are the test passes by luck!</span></p>
</section>
<section id="PBT">

    <h2>
    <a href="#PBT"><span>PBT</span> </a>
    </h2>
<p><span>Of course the temptation is to apply property based testing here! The problem </span><em><span>almost</span></em><span> fits: we have</span>
<span>easy-to-generate input (the sequence of increments spread over several threads), a good property to</span>
<span>check (result of concurrent increments is identical to that of sequential execution) and the desire</span>
<span>to minimize the test.</span></p>
<p><span>But just how can we plug threads into a property-based test?</span></p>
<p><span>PBTs are great for testing state machines. You can run your state machine through a series of steps</span>
<span>where at each step a PBT selects an arbitrary next action to apply to the state:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-meta">#[test]</span></span>
<span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">state_machine_test</span>() {</span>
<span class="line">  arbtest::<span class="hl-title function_ invoke__">arbtest</span>(|rng| {</span>
<span class="line">    <span class="hl-comment">// This is our state machine!</span></span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">state</span>: <span class="hl-type">i32</span> = <span class="hl-number">0</span>;</span>
<span class="line"></span>
<span class="line">    <span class="hl-comment">// We&#x27;ll run it for up to 100 steps.</span></span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">step_count</span>: <span class="hl-type">usize</span> = rng.<span class="hl-title function_ invoke__">int_in_range</span>(<span class="hl-number">0</span>..=<span class="hl-number">100</span>)?;</span>
<span class="line"></span>
<span class="line">    <span class="hl-keyword">for</span> <span class="hl-variable">_</span> <span class="hl-keyword">in</span> <span class="hl-number">0</span>..step_count {</span>
<span class="line">      <span class="hl-comment">// At each step, we flip a coin and</span></span>
<span class="line">      <span class="hl-comment">// either increment or decrement.</span></span>
<span class="line">      <span class="hl-keyword">match</span> *rng.<span class="hl-title function_ invoke__">choose</span>(&amp;[<span class="hl-string">&quot;inc&quot;</span>, <span class="hl-string">&quot;dec&quot;</span>])? {</span>
<span class="line">        <span class="hl-string">&quot;inc&quot;</span> =&gt; state += <span class="hl-number">1</span>,</span>
<span class="line">        <span class="hl-string">&quot;dec&quot;</span> =&gt; state -= <span class="hl-number">1</span>,</span>
<span class="line">        _ =&gt; <span class="hl-built_in">unreachable!</span>(),</span>
<span class="line">      }</span>
<span class="line">    }</span>
<span class="line">    <span class="hl-title function_ invoke__">Ok</span>(())</span>
<span class="line">  });</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>And it </span><em><span>feels</span></em><span> like we should be able to apply the same technique here. At every iteration, pick a</span>
<span>random thread and make it do a single step. If you can step the threads manually, it should be easy</span>
<span>to maneuver one thread in between load&amp;store of a different thread.</span></p>
<p><span>But we can</span>&rsquo;<span>t step through threads! Or can we?</span></p>
</section>
<section id="Simple-Instrumentation">

    <h2>
    <a href="#Simple-Instrumentation"><span>Simple Instrumentation</span> </a>
    </h2>
<p><span>Ok, let</span>&rsquo;<span>s fake it until we make it! Let</span>&rsquo;<span>s take a look at the buggy increment method:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">increment</span>(&amp;<span class="hl-keyword">self</span>) {</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">value</span> = <span class="hl-keyword">self</span>.value.<span class="hl-title function_ invoke__">load</span>(SeqCst);</span>
<span class="line">  <span class="hl-keyword">self</span>.value.<span class="hl-title function_ invoke__">store</span>(value + <span class="hl-number">1</span>, SeqCst);</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>Ideally, we</span>&rsquo;<span>d love to be able to somehow </span>&ldquo;<span>pause</span>&rdquo;<span> the thread in-between atomic operations. Something</span>
<span>like this:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">increment</span>(&amp;<span class="hl-keyword">self</span>) {</span>
<span class="line">  <span class="hl-title function_ invoke__">pause</span>();</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">value</span> = <span class="hl-keyword">self</span>.value.<span class="hl-title function_ invoke__">load</span>(SeqCst);</span>
<span class="line">  <span class="hl-title function_ invoke__">pause</span>();</span>
<span class="line">  <span class="hl-keyword">self</span>.value.<span class="hl-title function_ invoke__">store</span>(value + <span class="hl-number">1</span>, SeqCst);</span>
<span class="line">  <span class="hl-title function_ invoke__">pause</span>();</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">pause</span>() {</span>
<span class="line">    <span class="hl-comment">// ¯\_(ツ)_/¯</span></span>
<span class="line">}</span></code></pre>

</figure>
<p><span>So let</span>&rsquo;<span>s start with implementing our own wrapper for </span><code>AtomicU32</code><span> which includes calls to pause.</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">use</span> std::sync::atomic::Ordering;</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">struct</span> <span class="hl-title class_">AtomicU32</span> {</span>
<span class="line">  inner: std::sync::atomic::AtomicU32,</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">AtomicU32</span> {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">load</span>(&amp;<span class="hl-keyword">self</span>, ordering: Ordering) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">u32</span> {</span>
<span class="line">    <span class="hl-title function_ invoke__">pause</span>();</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">result</span> = <span class="hl-keyword">self</span>.inner.<span class="hl-title function_ invoke__">load</span>(ordering);</span>
<span class="line">    <span class="hl-title function_ invoke__">pause</span>();</span>
<span class="line">    result</span>
<span class="line">  }</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">store</span>(&amp;<span class="hl-keyword">self</span>, value: <span class="hl-type">u32</span>, ordering: Ordering) {</span>
<span class="line">    <span class="hl-title function_ invoke__">pause</span>();</span>
<span class="line">    <span class="hl-keyword">self</span>.inner.<span class="hl-title function_ invoke__">store</span>(value, ordering);</span>
<span class="line">    <span class="hl-title function_ invoke__">pause</span>();</span>
<span class="line">  }</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">pause</span>() {</span>
<span class="line">  <span class="hl-comment">// still no idea :(</span></span>
<span class="line">}</span></code></pre>

</figure>
</section>
<section id="Managed-Threads-API">

    <h2>
    <a href="#Managed-Threads-API"><span>Managed Threads API</span> </a>
    </h2>
<p><span>One rule of a great API design is that you start by implement a single </span><em><span>user</span></em><span> of an API, to</span>
<span>understand how the API should </span><em><span>feel</span></em><span>, and only then proceed to the actual implementation.</span></p>
<p><span>So, in the spirit of faking, let</span>&rsquo;<span>s just write a PBT using these pausable, managed threads, even if</span>
<span>we still have no idea how to actually implement pausing.</span></p>
<p><span>We start with creating a counter and two managed threads. And we probably want to pass a reference</span>
<span>to the counter to each of the threads:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">let</span> <span class="hl-variable">counter</span> = Counter::<span class="hl-title function_ invoke__">default</span>();</span>
<span class="line"><span class="hl-keyword">let</span> <span class="hl-variable">t1</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>(&amp;counter);</span>
<span class="line"><span class="hl-keyword">let</span> <span class="hl-variable">t2</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>(&amp;counter);</span></code></pre>

</figure>
<p><span>Now, we want to step through the threads:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">while</span> !rng.<span class="hl-title function_ invoke__">is_empty</span>() {</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">coin_flip</span>: <span class="hl-type">bool</span> = rng.<span class="hl-title function_ invoke__">arbitrary</span>()?;</span>
<span class="line">  <span class="hl-keyword">if</span> t1.<span class="hl-title function_ invoke__">is_paused</span>() {</span>
<span class="line">    <span class="hl-keyword">if</span> coin_flip {</span>
<span class="line">      t1.<span class="hl-title function_ invoke__">unpause</span>();</span>
<span class="line">    }</span>
<span class="line">  }</span>
<span class="line">  <span class="hl-keyword">if</span> t2.<span class="hl-title function_ invoke__">is_paused</span>() {</span>
<span class="line">    <span class="hl-keyword">if</span> coin_flip {</span>
<span class="line">      t2.<span class="hl-title function_ invoke__">unpause</span>();</span>
<span class="line">    }</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>Or, refactoring this a bit to semantically compress:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">let</span> <span class="hl-variable">counter</span> = Counter::<span class="hl-title function_ invoke__">default</span>();</span>
<span class="line"><span class="hl-keyword">let</span> <span class="hl-variable">t1</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>(&amp;counter);</span>
<span class="line"><span class="hl-keyword">let</span> <span class="hl-variable">t2</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>(&amp;counter);</span>
<span class="line"><span class="hl-keyword">let</span> <span class="hl-variable">threads</span> = [t1, t2];</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">while</span> !rng.<span class="hl-title function_ invoke__">is_empty</span>() {</span>
<span class="line">  <span class="hl-keyword">for</span> <span class="hl-variable">t</span> <span class="hl-keyword">in</span> &amp;<span class="hl-keyword">mut</span> threads {</span>
<span class="line">    <span class="hl-keyword">if</span> t.<span class="hl-title function_ invoke__">is_paused</span>() &amp;&amp; rng.<span class="hl-title function_ invoke__">arbitrary</span>()? {</span>
<span class="line">      t.<span class="hl-title function_ invoke__">unpause</span>()</span>
<span class="line">    }</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>That is, on each step of our state machine, we loop through all threads and unpause a random subset</span>
<span>of them.</span></p>
<p><span>But besides pausing and unpausing, we need our threads to actually </span><em><span>do</span></em><span> something, to increment the</span>
<span>counter. One idea is to mirror the </span><code>std::spawn</code><span> API and pass a closure in:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">let</span> <span class="hl-variable">t1</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>({</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">counter</span> = &amp;counter;</span>
<span class="line">  <span class="hl-keyword">move</span> || {</span>
<span class="line">    <span class="hl-keyword">for</span> <span class="hl-variable">_</span> <span class="hl-keyword">in</span> <span class="hl-number">0</span>..<span class="hl-number">100</span> {</span>
<span class="line">      counter.<span class="hl-title function_ invoke__">increment</span>();</span>
<span class="line">    }</span>
<span class="line">  }</span>
<span class="line">});</span></code></pre>

</figure>
<p><span>But as these are managed threads, and we want to control them from our tests, lets actually go all</span>
<span>the way there and give the controlling thread an ability to change the code running in a managed</span>
<span>thread. That is, we</span>&rsquo;<span>ll start managed threads without a </span>&ldquo;<span>main</span>&rdquo;<span> function, and provide an API to</span>
<span>execute arbitrary closures in the context of this by-default inert thread (</span><a href="https://joearms.github.io/published/2013-11-21-My-favorite-erlang-program.html"><span>universal</span>
<span>server</span></a><span> anyone?):</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">let</span> <span class="hl-variable">counter</span> = Counter::<span class="hl-title function_ invoke__">default</span>();</span>
<span class="line"></span>
<span class="line"><span class="hl-comment">// We pass the state, &amp;counter, in, but otherwise the thread is inert.</span></span>
<span class="line"><span class="hl-keyword">let</span> <span class="hl-variable">t</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>(&amp;counter);</span>
<span class="line"></span>
<span class="line"><span class="hl-comment">// But we can manually poke it:</span></span>
<span class="line">t.<span class="hl-title function_ invoke__">submit</span>(|thread_state: &amp;Counter| thread_state.<span class="hl-title function_ invoke__">increment</span>());</span>
<span class="line">t.<span class="hl-title function_ invoke__">submit</span>(|thread_state: &amp;Counter| thread_state.<span class="hl-title function_ invoke__">increment</span>());</span></code></pre>

</figure>
<p><span>Putting everything together, we get a nice-looking property test:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-meta">#[cfg(test)]</span></span>
<span class="line"><span class="hl-keyword">use</span> managed_thread::AtomicU32;</span>
<span class="line"><span class="hl-meta">#[cfg(not(test))]</span></span>
<span class="line"><span class="hl-keyword">use</span> std::sync::atomic::AtomicU32;</span>
<span class="line"></span>
<span class="line"><span class="hl-meta">#[derive(Default)]</span></span>
<span class="line"><span class="hl-keyword">pub</span> <span class="hl-keyword">struct</span> <span class="hl-title class_">Counter</span> {</span>
<span class="line">  value: AtomicU32,</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">Counter</span> {</span>
<span class="line">  <span class="hl-comment">// ...</span></span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-meta">#[test]</span></span>
<span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">test_counter</span>() {</span>
<span class="line">  arbtest::<span class="hl-title function_ invoke__">arbtest</span>(|rng| {</span>
<span class="line">    <span class="hl-comment">// Our &quot;Concurrent System Under Test&quot;.</span></span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">counter</span> = Counter::<span class="hl-title function_ invoke__">default</span>();</span>
<span class="line"></span>
<span class="line">    <span class="hl-comment">// The sequential model we&#x27;ll compare the result against.</span></span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">counter_model</span>: <span class="hl-type">u32</span> = <span class="hl-number">0</span>;</span>
<span class="line"></span>
<span class="line">    <span class="hl-comment">// Two managed threads which we will be stepping through</span></span>
<span class="line">    <span class="hl-comment">// manually.</span></span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">t1</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>(&amp;counter);</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">t2</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>(&amp;counter);</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">threads</span> = [t1, t2];</span>
<span class="line"></span>
<span class="line">    <span class="hl-comment">// Bulk of the test: in a loop, flip a coin and advance</span></span>
<span class="line">    <span class="hl-comment">// one of the threads.</span></span>
<span class="line">    <span class="hl-keyword">while</span> !rng.<span class="hl-title function_ invoke__">is_empty</span>() {</span>
<span class="line">      <span class="hl-keyword">for</span> <span class="hl-variable">t</span> <span class="hl-keyword">in</span> &amp;<span class="hl-keyword">mut</span> [t1, t2] {</span>
<span class="line">        <span class="hl-keyword">if</span> rng.<span class="hl-title function_ invoke__">arbitrary</span>() {</span>
<span class="line">          <span class="hl-keyword">if</span> t.<span class="hl-title function_ invoke__">is_paused</span>() {</span>
<span class="line">            t.<span class="hl-title function_ invoke__">unpause</span>()</span>
<span class="line">          } <span class="hl-keyword">else</span> {</span>
<span class="line">            <span class="hl-comment">// Standard &quot;model equivalence&quot; property: apply</span></span>
<span class="line">            <span class="hl-comment">// isomorphic actions to the system and its model.</span></span>
<span class="line">            t.<span class="hl-title function_ invoke__">submit</span>(|c| c.<span class="hl-title function_ invoke__">increment</span>());</span>
<span class="line">            counter_model += <span class="hl-number">1</span>;</span>
<span class="line">          }</span>
<span class="line">        }</span>
<span class="line">      }</span>
<span class="line">    }</span>
<span class="line"></span>
<span class="line">    <span class="hl-keyword">for</span> <span class="hl-variable">t</span> <span class="hl-keyword">in</span> threads {</span>
<span class="line">      t.<span class="hl-title function_ invoke__">join</span>();</span>
<span class="line">    }</span>
<span class="line"></span>
<span class="line">    <span class="hl-built_in">assert_eq!</span>(counter_model, counter.<span class="hl-title function_ invoke__">get</span>());</span>
<span class="line"></span>
<span class="line">    <span class="hl-title function_ invoke__">Ok</span>(())</span>
<span class="line">  });</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>Now, if only we could make this API work</span>&hellip;<span> Remember, our </span><code>pause</code><span> implementation is a shrug emoji!</span></p>
<p><span>At this point, you might be mightily annoyed at me for this rhetorical device where I pretend that I</span>
<span>don</span>&rsquo;<span>t know the answer. No need for annoyance </span>&mdash;<span> when writing this code for the first time, I traced</span>
<span>exactly these steps </span>&mdash;<span> I realized that I need a </span>&ldquo;<span>pausing </span><code>AtomicU32</code>&rdquo;<span> so I did that (with dummy</span>
<span>pause calls), then I played with the API I </span><em><span>wanted</span></em><span> to have, ending at roughly this spot, without</span>
<span>yet knowing how I would make it work or, indeed, if it is possible at all.</span></p>
<p><span>Well, if I am being honest, there is a bit of up-front knowledge here. I don</span>&rsquo;<span>t think we can avoid</span>
<span>spawning real threads here, unless we do something really cursed with inline assembly. When</span>
<em><span>something</span></em><span> calls that </span><code>pause()</code><span> function, and we want it to stay paused until further notice, that</span>
<span>just has to happen in a thread which maintains a stack separate from the stack of our test. And, if</span>
<span>we are going to spawn threads, we might as well spawn scoped threads, so that we can freely borrow</span>
<span>stack-local data. And to spawn a scope thread, you need a</span>
<a href="https://doc.rust-lang.org/stable/std/thread/struct.Scope.html"><code>Scope</code></a><span> parameter. So in reality</span>
<span>we</span>&rsquo;<span>ll need one more level of indentation here:</span></p>

<figure class="code-block">


<pre><code><span class="line">    std::thread::<span class="hl-title function_ invoke__">scope</span>(|scope| {</span>
<span class="line">      <span class="hl-keyword">let</span> <span class="hl-variable">t1</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>(scope, &amp;counter);</span>
<span class="line">      <span class="hl-keyword">let</span> <span class="hl-variable">t2</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>(scope, &amp;counter);</span>
<span class="line">      <span class="hl-keyword">let</span> <span class="hl-variable">threads</span> = [t1, t2];</span>
<span class="line">      <span class="hl-keyword">while</span> !rng.<span class="hl-title function_ invoke__">is_empty</span>() {</span>
<span class="line">        <span class="hl-keyword">for</span> <span class="hl-variable">t</span> <span class="hl-keyword">in</span> &amp;<span class="hl-keyword">mut</span> [t1, t2] {</span>
<span class="line">          <span class="hl-comment">// ...</span></span>
<span class="line">        }</span>
<span class="line">      }</span>
<span class="line">    });</span></code></pre>

</figure>
</section>
<section id="Managed-Threads-Implementation">

    <h2>
    <a href="#Managed-Threads-Implementation"><span>Managed Threads Implementation</span> </a>
    </h2>
<p><span>Now, the fun part: how the heck are we going to make pausing and unpausing work? For starters, there</span>
<span>clearly needs to be some communication between the main thread (</span><code>t.unpause()</code><span>) and the managed</span>
<span>thread (</span><code>pause()</code><span>). And, because we don</span>&rsquo;<span>t want to change </span><code>Counter</code><span> API to thread some kind of</span>
<span>test-only context, the context needs to be smuggled. So </span><code>thread_local!</code><span> it is. And this context</span>
<span>is going to be shared between two threads, so it must be wrapped in an </span><code>Arc</code><span>.</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">struct</span> <span class="hl-title class_">SharedContext</span> {</span>
<span class="line">  <span class="hl-comment">// 🤷</span></span>
<span class="line">}</span>
<span class="line"></span>
<span class="line">thread_local! {</span>
<span class="line">  <span class="hl-keyword">static</span> INSTANCE: RefCell&lt;<span class="hl-type">Option</span>&lt;Arc&lt;SharedContext&gt;&gt;&gt; =</span>
<span class="line">    RefCell::<span class="hl-title function_ invoke__">new</span>(<span class="hl-literal">None</span>);</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">SharedContext</span> {</span>
<span class="line">  <span class="hl-keyword">fn</span> <span class="hl-title function_">set</span>(ctx: Arc&lt;SharedContext&gt;) {</span>
<span class="line">    INSTANCE.<span class="hl-title function_ invoke__">with</span>(|it| *it.<span class="hl-title function_ invoke__">borrow_mut</span>() = <span class="hl-title function_ invoke__">Some</span>(ctx));</span>
<span class="line">  }</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">fn</span> <span class="hl-title function_">get</span>() <span class="hl-punctuation">-&gt;</span> <span class="hl-type">Option</span>&lt;Arc&lt;SharedContext&gt;&gt; {</span>
<span class="line">    INSTANCE.<span class="hl-title function_ invoke__">with</span>(|it| it.<span class="hl-title function_ invoke__">borrow</span>().<span class="hl-title function_ invoke__">clone</span>())</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>As usual when using </span><code>thread_local!</code><span> or </span><code>lazy_static!</code><span>, it is convenient to immediately wrap it into</span>
<span>better typed accessor functions. And, given that we are using an </span><code>Arc</code><span> here anyway, we can</span>
<span>conveniently escape </span><code>thread_local</code>&rsquo;<span>s </span><code>with</code><span> by cloning the </span><code>Arc</code><span>.</span></p>
<p><span>So now we finally can implement the global </span><code>pause</code><span> function (or at least can kick the proverbial can</span>
<span>a little bit farther):</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">pause</span>() {</span>
<span class="line">  <span class="hl-keyword">if</span> <span class="hl-keyword">let</span> <span class="hl-variable">Some</span>(ctx) = SharedContext::<span class="hl-title function_ invoke__">get</span>() {</span>
<span class="line">    ctx.<span class="hl-title function_ invoke__">pause</span>()</span>
<span class="line">  }</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">SharedContext</span> {</span>
<span class="line">  <span class="hl-keyword">fn</span> <span class="hl-title function_">pause</span>(&amp;<span class="hl-keyword">self</span>) {</span>
<span class="line">    <span class="hl-comment">// 😕</span></span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>Ok, what to do next? We somehow need to coordinate the control thread and the managed thread. And we</span>
<span>need some sort of notification mechanism, so that the managed thread knows when it can continue. The</span>
<span>most brute force solution here is a pair of a mutex protecting some state and a condition variable.</span>
<span>Mutex guards the state that can be manipulated by either of the threads. Condition variable can be</span>
<span>used to signal about the changes.</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">struct</span> <span class="hl-title class_">SharedContext</span> {</span>
<span class="line">  state: Mutex&lt;State&gt;,</span>
<span class="line">  cv: Condvar,</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">struct</span> <span class="hl-title class_">State</span> {</span>
<span class="line">  <span class="hl-comment">// 🤡</span></span>
<span class="line">}</span></code></pre>

</figure>
<p><span>Okay, it looks like I am running out of emojies here. There</span>&rsquo;<span>s no more layers of indirection or</span>
<span>infrastructure left, we need to write some real code that actually does do that pausing thing. So</span>
<span>let</span>&rsquo;<span>s say that the state is tracking, well, the state of our managed thread, which can be either</span>
<span>running or paused:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-meta">#[derive(PartialEq, Eq, Default)]</span></span>
<span class="line"><span class="hl-keyword">enum</span> <span class="hl-title class_">State</span> {</span>
<span class="line">  <span class="hl-meta">#[default]</span></span>
<span class="line">  Running,</span>
<span class="line">  Paused,</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>And then the logic of the pause function </span>&mdash;<span> flip the state from </span><code>Running</code><span> to </span><code>Paused</code><span>, notify the</span>
<span>controlling thread that we are </span><code>Paused</code><span>, and wait until the controlling thread flips our state back</span>
<span>to </span><code>Running</code><span>:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">SharedContext</span> {</span>
<span class="line">  <span class="hl-keyword">fn</span> <span class="hl-title function_">pause</span>(&amp;<span class="hl-keyword">self</span>) {</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">guard</span> = <span class="hl-keyword">self</span>.state.<span class="hl-title function_ invoke__">lock</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">    <span class="hl-built_in">assert_eq!</span>(*guard, State::Running);</span>
<span class="line">    *guard = State::Paused;</span>
<span class="line">    <span class="hl-keyword">self</span>.cv.<span class="hl-title function_ invoke__">notify_all</span>();</span>
<span class="line">    <span class="hl-keyword">while</span> *guard == State::Paused {</span>
<span class="line">      guard = <span class="hl-keyword">self</span>.cv.<span class="hl-title function_ invoke__">wait</span>(guard).<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">    }</span>
<span class="line">    <span class="hl-built_in">assert_eq!</span>(*guard, State::Running);</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>Aside: Rust</span>&rsquo;<span>s API for condition variables is beautiful. Condvars are tricky, and I didn</span>&rsquo;<span>t really</span>
<span>understood them until seeing the signatures of Rust functions. Notice how the </span><code>wait</code><span> function</span>
<em><span>takes</span></em><span> a mutex guard as an argument, and returns a mutex guard. This protects you from the logical</span>
<span>races and guides you towards the standard pattern of using condvars:</span></p>
<p><span>First, you lock the mutex around the shared state. Then, you inspect whether the state is what you</span>
<span>need. If that</span>&rsquo;<span>s the case, great, you do what you wanted to do and unlock the mutex. If not, then,</span>
<em><span>while still holding the mutex</span></em><span>, you </span><em><span>wait</span></em><span> on the condition variable. Which means that the</span>
<span>mutex gets unlocked, and other threads get the chance to change the shared state. When they do</span>
<span>change it, and notify the condvar, your thread wakes up, and it gets the locked mutex back (but the</span>
<span>state now is different). Due to the possibility of spurious wake-ups, you need to double check the</span>
<span>state and be ready to loop back again to waiting.</span></p>
<p><span>Naturally, there</span>&rsquo;<span>s a helper that encapsulates this whole pattern:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">SharedContext</span> {</span>
<span class="line">  <span class="hl-keyword">fn</span> <span class="hl-title function_">pause</span>(&amp;<span class="hl-keyword">self</span>) {</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">guard</span> = <span class="hl-keyword">self</span>.state.<span class="hl-title function_ invoke__">lock</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">    <span class="hl-built_in">assert_eq!</span>(*guard, State::Running);</span>
<span class="line">    *guard = State::Paused;</span>
<span class="line">    <span class="hl-keyword">self</span>.cv.<span class="hl-title function_ invoke__">notify_all</span>();</span>
<span class="line">    guard = <span class="hl-keyword">self</span></span>
<span class="line">      .cv</span>
<span class="line">      .<span class="hl-title function_ invoke__">wait_while</span>(guard, |state| *state == State::Paused)</span>
<span class="line">      .<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">    <span class="hl-built_in">assert_eq!</span>(*guard, State::Running)</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>Ok, this actually does look like a reasonable implementation of </span><code>pause</code><span>. Let</span>&rsquo;<span>s move on to</span>
<code>managed_thread::spawn</code><span>:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">spawn</span>&lt;<span class="hl-symbol">&#x27;scope</span>, T: <span class="hl-symbol">&#x27;scope</span> + <span class="hl-built_in">Send</span>&gt;(</span>
<span class="line">  scope: &amp;Scope&lt;<span class="hl-symbol">&#x27;scope</span>, <span class="hl-symbol">&#x27;_</span>&gt;,</span>
<span class="line">  state: T,</span>
<span class="line">) {</span>
<span class="line">  <span class="hl-comment">// ? ? ?? ??? ?????</span></span>
<span class="line">}</span></code></pre>

</figure>
<p><span>There</span>&rsquo;<span>s a bunch of stuff that needs to happen here:</span></p>
<ul>
<li>
<span>As we have established, we are going to spawn a (scoped) thread, so we need the </span><code>scope</code><span> parameter</span>
<span>with its three lifetimes. I don</span>&rsquo;<span>t know how it works, so I am just going by the docs here!</span>
</li>
<li>
<span>We are going to return some kind of handle, which we can use to pause and unpause our managed</span>
<span>thread. And that handle is going to be parametrized over the same </span><code>'scope</code><span> lifetime, because it</span>&rsquo;<span>ll</span>
<span>hold onto the actual join handle.</span>
</li>
<li>
<span>We are going to pass the generic state to our new thread, and that state needs to be </span><code>Send</code><span>, and</span>
<span>bounded by the same lifetime as our scoped thread.</span>
</li>
<li>
<span>Inside, we are going to spawn a thread for sure, and we</span>&rsquo;<span>ll need to setup the </span><code>INSTANCE</code><span> thread</span>
<span>local on that thread.</span>
</li>
<li>
<span>And it would actually be a good idea to stuff a reference to that </span><code>SharedContext</code><span> into the handle</span>
<span>we return.</span>
</li>
</ul>
<p><span>A bunch of stuff, in other words. Let</span>&rsquo;<span>s do it:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">struct</span> <span class="hl-title class_">ManagedHandle</span>&lt;<span class="hl-symbol">&#x27;scope</span>&gt; {</span>
<span class="line">  inner: std::thread::ScopedJoinHandle&lt;<span class="hl-symbol">&#x27;scope</span>, ()&gt;,</span>
<span class="line">  ctx: Arc&lt;SharedContext&gt;,</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">spawn</span>&lt;<span class="hl-symbol">&#x27;scope</span>, T: <span class="hl-symbol">&#x27;scope</span> + <span class="hl-built_in">Send</span>&gt;(</span>
<span class="line">  scope: &amp;<span class="hl-symbol">&#x27;scope</span> Scope&lt;<span class="hl-symbol">&#x27;scope</span>, <span class="hl-symbol">&#x27;_</span>&gt;,</span>
<span class="line">  state: T,</span>
<span class="line">) <span class="hl-punctuation">-&gt;</span> ManagedHandle&lt;<span class="hl-symbol">&#x27;scope</span>&gt; {</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">ctx</span>: Arc&lt;SharedContext&gt; = <span class="hl-built_in">Default</span>::<span class="hl-title function_ invoke__">default</span>();</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">inner</span> = scope.<span class="hl-title function_ invoke__">spawn</span>({</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">ctx</span> = Arc::<span class="hl-title function_ invoke__">clone</span>(&amp;ctx);</span>
<span class="line">    <span class="hl-keyword">move</span> || {</span>
<span class="line">      SharedContext::<span class="hl-title function_ invoke__">set</span>(ctx);</span>
<span class="line">      <span class="hl-title function_ invoke__">drop</span>(state); <span class="hl-comment">// <span class="hl-doctag">TODO:</span> ¿</span></span>
<span class="line">    }</span>
<span class="line">  });</span>
<span class="line">  ManagedHandle { inner, ctx }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>The essentially no-op function we spawn looks sus. We</span>&rsquo;<span>ll fix later! Let</span>&rsquo;<span>s try to implement</span>
<code>is_paused</code><span> and </span><code>unpause</code><span> first! They should be relatively straightforward. For </span><code>is_paused</code><span>, we just</span>
<span>need to lock the mutex and check the state:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">ManagedHandle</span>&lt;<span class="hl-symbol">&#x27;_</span>&gt; {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">is_paused</span>(&amp;<span class="hl-keyword">self</span>,) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">bool</span> {</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">guard</span> = <span class="hl-keyword">self</span>.ctx.state.<span class="hl-title function_ invoke__">lock</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">    *guard == State::Paused</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>For </span><code>unpause</code><span>, we should additionally flip the state back to </span><code>Running</code><span> and notify the other thread:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">ManagedHandle</span>&lt;<span class="hl-symbol">&#x27;_</span>&gt; {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">unpause</span>(&amp;<span class="hl-keyword">self</span>) {</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">guard</span> = <span class="hl-keyword">self</span>.ctx.state.<span class="hl-title function_ invoke__">lock</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">    <span class="hl-built_in">assert_eq!</span>(*guard, State::Paused);</span>
<span class="line">    *guard = State::Running;</span>
<span class="line">    <span class="hl-keyword">self</span>.ctx.cv.<span class="hl-title function_ invoke__">notify_all</span>();</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>But I think that</span>&rsquo;<span>s not quite correct. Can you see why?</span></p>
<p><span>With this implementation, after </span><code>unpause</code><span>, the controlling and the managed threads will be running</span>
<span>concurrently. And that can lead to non-determinism, the very problem we are trying to avoid here! In</span>
<span>particular, if you call </span><code>is_paused</code><span> </span><em><span>right</span></em><span> after you </span><code>unpause</code><span> the thread, you</span>&rsquo;<span>ll most likely get</span>
<code>false</code><span> back, as the other thread will still be running. But it might also hit the </span><em><span>next</span></em><span> </span><code>pause</code>
<span>call, so, depending on timing, you might also get </span><code>true</code><span>.</span></p>
<p><span>What we want is actually completely eliminating all unmanaged concurrency. That means that at any</span>
<span>given point in time, only one thread (controlling or managed) should be running. So the right</span>
<span>semantics for </span><code>unpause</code><span> is to unblock the managed thread, and then block the controlling thread</span>
<span>until the managed one hits the next pause!</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">ManagedHandle</span>&lt;<span class="hl-symbol">&#x27;_</span>&gt; {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">unpause</span>(&amp;<span class="hl-keyword">self</span>) {</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">guard</span> = <span class="hl-keyword">self</span>.ctx.state.<span class="hl-title function_ invoke__">lock</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">    <span class="hl-built_in">assert_eq!</span>(*guard, State::Paused);</span>
<span class="line">    *guard = State::Running;</span>
<span class="line">    <span class="hl-keyword">self</span>.ctx.cv.<span class="hl-title function_ invoke__">notify_all</span>();</span>
<span class="line">    guard = <span class="hl-keyword">self</span></span>
<span class="line">      .ctx</span>
<span class="line">      .cv</span>
<span class="line">      .<span class="hl-title function_ invoke__">wait_while</span>(guard, |state| *state == State::Running)</span>
<span class="line">      .<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>At this point we can spawn a managed thread, pause it and resume. But right now it doesn</span>&rsquo;<span>t do</span>
<span>anything. Next step is implementing that idea where the controlling thread can directly send an</span>
<span>arbitrary closure to the managed one to make it do something:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">impl</span>&lt;<span class="hl-symbol">&#x27;scope</span>&gt; ManagedHandle&lt;<span class="hl-symbol">&#x27;scope</span>&gt; {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">submit</span>&lt;F: FnSomething&gt;(&amp;<span class="hl-keyword">self</span>, f: F)</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>Let</span>&rsquo;<span>s figure this </span><code>FnSomething</code><span> bound! We are going to yeet this </span><code>f</code><span> over to the managed thread and</span>
<span>run it there once, so it is </span><code>FnOnce</code><span>. It is crossing thread-boundary, so it needs to be </span><code>+ Send</code><span>.</span>
<span>And, because we are using scoped threads, it </span><em><span>doesn</span>&rsquo;<span>t</span></em><span> have to be </span><code>'static</code><span>, just </span><code>'scope</code><span> is</span>
<span>enough. Moreover, in that managed thread the </span><code>f</code><span> will have exclusive access to thread</span>&rsquo;<span>s state, </span><code>T</code><span>.</span>
<span>So we have:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">impl</span>&lt;<span class="hl-symbol">&#x27;scope</span>&gt; ManagedHandle&lt;<span class="hl-symbol">&#x27;scope</span>&gt; {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">submit</span>&lt;F: <span class="hl-title function_ invoke__">FnOnce</span>(&amp;<span class="hl-keyword">mut</span> T) + <span class="hl-built_in">Send</span> + <span class="hl-symbol">&#x27;scope</span>&gt;(<span class="hl-keyword">self</span>, f: F)</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>Implementing this is a bit tricky. First, we</span>&rsquo;<span>ll need some sort of the channel to actually move the</span>
<span>function. Then, similarly to the </span><code>unpause</code><span> logic, we</span>&rsquo;<span>ll need synchronization to make sure that the</span>
<span>control thread doesn</span>&rsquo;<span>t resume until the managed thread starts running </span><code>f</code><span> and hits a pause (or maybe</span>
<span>completes </span><code>f</code><span>). And we</span>&rsquo;<span>ll also need a new state, </span><code>Ready</code><span>, because now there are two different</span>
<span>reasons why a managed thread might be blocked </span>&mdash;<span> it might wait for an </span><code>unpause</code><span> event, or it might</span>
<span>wait for the next </span><code>f</code><span> to execute. This is the new code:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-meta">#[derive(Default)]</span></span>
<span class="line"><span class="hl-keyword">enum</span> <span class="hl-title class_">State</span> {</span>
<span class="line hl-line">  <span class="hl-meta">#[default]</span></span>
<span class="line hl-line">  Ready,</span>
<span class="line">  Running,</span>
<span class="line">  Paused,</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line hl-line"><span class="hl-keyword">struct</span> <span class="hl-title class_">ManagedHandle</span>&lt;<span class="hl-symbol">&#x27;scope</span>, T&gt; {</span>
<span class="line">  inner: std::thread::ScopedJoinHandle&lt;<span class="hl-symbol">&#x27;scope</span>, ()&gt;,</span>
<span class="line">  ctx: Arc&lt;SharedContext&gt;,</span>
<span class="line hl-line">  sender: mpsc::Sender&lt;<span class="hl-type">Box</span>&lt;<span class="hl-keyword">dyn</span> <span class="hl-title function_ invoke__">FnOnce</span>(&amp;<span class="hl-keyword">mut</span> T) + <span class="hl-symbol">&#x27;scope</span> + <span class="hl-built_in">Send</span>&gt;&gt;,</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">spawn</span>&lt;<span class="hl-symbol">&#x27;scope</span>, T: <span class="hl-symbol">&#x27;scope</span> + <span class="hl-built_in">Send</span>&gt;(</span>
<span class="line">  scope: &amp;<span class="hl-symbol">&#x27;scope</span> Scope&lt;<span class="hl-symbol">&#x27;scope</span>, <span class="hl-symbol">&#x27;_</span>&gt;,</span>
<span class="line">  <span class="hl-keyword">mut</span> state: T,</span>
<span class="line">) <span class="hl-punctuation">-&gt;</span> ManagedHandle&lt;<span class="hl-symbol">&#x27;scope</span>, T&gt; {</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">ctx</span>: Arc&lt;SharedContext&gt; = <span class="hl-built_in">Default</span>::<span class="hl-title function_ invoke__">default</span>();</span>
<span class="line hl-line">  <span class="hl-keyword">let</span> (sender, receiver) =</span>
<span class="line hl-line">    mpsc::channel::&lt;<span class="hl-type">Box</span>&lt;<span class="hl-keyword">dyn</span> <span class="hl-title function_ invoke__">FnOnce</span>(&amp;<span class="hl-keyword">mut</span> T) + <span class="hl-symbol">&#x27;scope</span> + <span class="hl-built_in">Send</span>&gt;&gt;();</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">inner</span> = scope.<span class="hl-title function_ invoke__">spawn</span>({</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">ctx</span> = Arc::<span class="hl-title function_ invoke__">clone</span>(&amp;ctx);</span>
<span class="line">    <span class="hl-keyword">move</span> || {</span>
<span class="line">      SharedContext::<span class="hl-title function_ invoke__">set</span>(Arc::<span class="hl-title function_ invoke__">clone</span>(&amp;ctx));</span>
<span class="line"></span>
<span class="line hl-line">      <span class="hl-keyword">for</span> <span class="hl-variable">f</span> <span class="hl-keyword">in</span> receiver {</span>
<span class="line hl-line">        <span class="hl-title function_ invoke__">f</span>(&amp;<span class="hl-keyword">mut</span> state);</span>
<span class="line hl-line"></span>
<span class="line hl-line">        <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">guard</span> = ctx.state.<span class="hl-title function_ invoke__">lock</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line hl-line">        <span class="hl-built_in">assert_eq!</span>(*guard, State::Running);</span>
<span class="line hl-line">        *guard = State::Ready;</span>
<span class="line hl-line">        ctx.cv.<span class="hl-title function_ invoke__">notify_all</span>()</span>
<span class="line hl-line">      }</span>
<span class="line">    }</span>
<span class="line">  });</span>
<span class="line">  ManagedHandle { inner, ctx, sender }</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">impl</span>&lt;<span class="hl-symbol">&#x27;scope</span>, T&gt; ManagedHandle&lt;<span class="hl-symbol">&#x27;scope</span>, T&gt; {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">submit</span>&lt;F: <span class="hl-title function_ invoke__">FnOnce</span>(&amp;<span class="hl-keyword">mut</span> T) + <span class="hl-built_in">Send</span> + <span class="hl-symbol">&#x27;scope</span>&gt;(&amp;<span class="hl-keyword">self</span>, f: F) {</span>
<span class="line hl-line">    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">guard</span> = <span class="hl-keyword">self</span>.ctx.state.<span class="hl-title function_ invoke__">lock</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line hl-line">    <span class="hl-built_in">assert_eq!</span>(*guard, State::Ready);</span>
<span class="line hl-line">    *guard = State::Running;</span>
<span class="line hl-line">    <span class="hl-keyword">self</span>.sender.<span class="hl-title function_ invoke__">send</span>(<span class="hl-type">Box</span>::<span class="hl-title function_ invoke__">new</span>(f)).<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line hl-line">    guard = <span class="hl-keyword">self</span></span>
<span class="line hl-line">      .ctx</span>
<span class="line hl-line">      .cv</span>
<span class="line hl-line">      .<span class="hl-title function_ invoke__">wait_while</span>(guard, |state| *state == State::Running)</span>
<span class="line hl-line">      .<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>The last small piece of the puzzle is the </span><code>join</code><span> function. It</span>&rsquo;<span>s </span><em><span>almost</span></em><span> standard! First we close</span>
<span>our side of the channel. This serves as a natural stop signal for the other thread, so it exits.</span>
<span>Which in turn allows us to join it. The small wrinkle here is that the thread might be paused when</span>
<span>we try to join it, so we need to unpause it beforehand:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">impl</span>&lt;<span class="hl-symbol">&#x27;scope</span>, T&gt; ManagedHandle&lt;<span class="hl-symbol">&#x27;scope</span>, T&gt; {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">join</span>(<span class="hl-keyword">self</span>) {</span>
<span class="line">    <span class="hl-keyword">while</span> <span class="hl-keyword">self</span>.<span class="hl-title function_ invoke__">is_paused</span>() {</span>
<span class="line">      <span class="hl-keyword">self</span>.<span class="hl-title function_ invoke__">unpause</span>();</span>
<span class="line">    }</span>
<span class="line">    <span class="hl-title function_ invoke__">drop</span>(<span class="hl-keyword">self</span>.sender);</span>
<span class="line">    <span class="hl-keyword">self</span>.inner.<span class="hl-title function_ invoke__">join</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>That</span>&rsquo;<span>s it! Let</span>&rsquo;<span>s put everything together!</span></p>
<p><span>Helper library, </span><code>managed_thread.rs</code><span>:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">use</span> std::{</span>
<span class="line">  cell::RefCell,</span>
<span class="line">  sync::{atomic::Ordering, mpsc, Arc, Condvar, Mutex},</span>
<span class="line">  thread::Scope,</span>
<span class="line">};</span>
<span class="line"></span>
<span class="line"><span class="hl-meta">#[derive(Default)]</span></span>
<span class="line"><span class="hl-keyword">pub</span> <span class="hl-keyword">struct</span> <span class="hl-title class_">AtomicU32</span> {</span>
<span class="line">  inner: std::sync::atomic::AtomicU32,</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">AtomicU32</span> {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">load</span>(&amp;<span class="hl-keyword">self</span>, ordering: Ordering) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">u32</span> {</span>
<span class="line">    <span class="hl-title function_ invoke__">pause</span>();</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">result</span> = <span class="hl-keyword">self</span>.inner.<span class="hl-title function_ invoke__">load</span>(ordering);</span>
<span class="line">    <span class="hl-title function_ invoke__">pause</span>();</span>
<span class="line">    result</span>
<span class="line">  }</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">store</span>(&amp;<span class="hl-keyword">self</span>, value: <span class="hl-type">u32</span>, ordering: Ordering) {</span>
<span class="line">    <span class="hl-title function_ invoke__">pause</span>();</span>
<span class="line">    <span class="hl-keyword">self</span>.inner.<span class="hl-title function_ invoke__">store</span>(value, ordering);</span>
<span class="line">    <span class="hl-title function_ invoke__">pause</span>();</span>
<span class="line">  }</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">pause</span>() {</span>
<span class="line">  <span class="hl-keyword">if</span> <span class="hl-keyword">let</span> <span class="hl-variable">Some</span>(ctx) = SharedContext::<span class="hl-title function_ invoke__">get</span>() {</span>
<span class="line">    ctx.<span class="hl-title function_ invoke__">pause</span>()</span>
<span class="line">  }</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-meta">#[derive(Default)]</span></span>
<span class="line"><span class="hl-keyword">struct</span> <span class="hl-title class_">SharedContext</span> {</span>
<span class="line">  state: Mutex&lt;State&gt;,</span>
<span class="line">  cv: Condvar,</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-meta">#[derive(Default, PartialEq, Eq, Debug)]</span></span>
<span class="line"><span class="hl-keyword">enum</span> <span class="hl-title class_">State</span> {</span>
<span class="line">  <span class="hl-meta">#[default]</span></span>
<span class="line">  Ready,</span>
<span class="line">  Running,</span>
<span class="line">  Paused,</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line">thread_local! {</span>
<span class="line">  <span class="hl-keyword">static</span> INSTANCE: RefCell&lt;<span class="hl-type">Option</span>&lt;Arc&lt;SharedContext&gt;&gt;&gt; =</span>
<span class="line">    RefCell::<span class="hl-title function_ invoke__">new</span>(<span class="hl-literal">None</span>);</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">SharedContext</span> {</span>
<span class="line">  <span class="hl-keyword">fn</span> <span class="hl-title function_">set</span>(ctx: Arc&lt;SharedContext&gt;) {</span>
<span class="line">    INSTANCE.<span class="hl-title function_ invoke__">with</span>(|it| *it.<span class="hl-title function_ invoke__">borrow_mut</span>() = <span class="hl-title function_ invoke__">Some</span>(ctx));</span>
<span class="line">  }</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">fn</span> <span class="hl-title function_">get</span>() <span class="hl-punctuation">-&gt;</span> <span class="hl-type">Option</span>&lt;Arc&lt;SharedContext&gt;&gt; {</span>
<span class="line">    INSTANCE.<span class="hl-title function_ invoke__">with</span>(|it| it.<span class="hl-title function_ invoke__">borrow</span>().<span class="hl-title function_ invoke__">clone</span>())</span>
<span class="line">  }</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">fn</span> <span class="hl-title function_">pause</span>(&amp;<span class="hl-keyword">self</span>) {</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">guard</span> = <span class="hl-keyword">self</span>.state.<span class="hl-title function_ invoke__">lock</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">    <span class="hl-built_in">assert_eq!</span>(*guard, State::Running);</span>
<span class="line">    *guard = State::Paused;</span>
<span class="line">    <span class="hl-keyword">self</span>.cv.<span class="hl-title function_ invoke__">notify_all</span>();</span>
<span class="line">    guard = <span class="hl-keyword">self</span></span>
<span class="line">      .cv</span>
<span class="line">      .<span class="hl-title function_ invoke__">wait_while</span>(guard, |state| *state == State::Paused)</span>
<span class="line">      .<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">    <span class="hl-built_in">assert_eq!</span>(*guard, State::Running)</span>
<span class="line">  }</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">pub</span> <span class="hl-keyword">struct</span> <span class="hl-title class_">ManagedHandle</span>&lt;<span class="hl-symbol">&#x27;scope</span>, T&gt; {</span>
<span class="line">  inner: std::thread::ScopedJoinHandle&lt;<span class="hl-symbol">&#x27;scope</span>, ()&gt;,</span>
<span class="line">  sender: mpsc::Sender&lt;<span class="hl-type">Box</span>&lt;<span class="hl-keyword">dyn</span> <span class="hl-title function_ invoke__">FnOnce</span>(&amp;<span class="hl-keyword">mut</span> T) + <span class="hl-symbol">&#x27;scope</span> + <span class="hl-built_in">Send</span>&gt;&gt;,</span>
<span class="line">  ctx: Arc&lt;SharedContext&gt;,</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">spawn</span>&lt;<span class="hl-symbol">&#x27;scope</span>, T: <span class="hl-symbol">&#x27;scope</span> + <span class="hl-built_in">Send</span>&gt;(</span>
<span class="line">  scope: &amp;<span class="hl-symbol">&#x27;scope</span> Scope&lt;<span class="hl-symbol">&#x27;scope</span>, <span class="hl-symbol">&#x27;_</span>&gt;,</span>
<span class="line">  <span class="hl-keyword">mut</span> state: T,</span>
<span class="line">) <span class="hl-punctuation">-&gt;</span> ManagedHandle&lt;<span class="hl-symbol">&#x27;scope</span>, T&gt; {</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">ctx</span>: Arc&lt;SharedContext&gt; = <span class="hl-built_in">Default</span>::<span class="hl-title function_ invoke__">default</span>();</span>
<span class="line">  <span class="hl-keyword">let</span> (sender, receiver) =</span>
<span class="line">    mpsc::channel::&lt;<span class="hl-type">Box</span>&lt;<span class="hl-keyword">dyn</span> <span class="hl-title function_ invoke__">FnOnce</span>(&amp;<span class="hl-keyword">mut</span> T) + <span class="hl-symbol">&#x27;scope</span> + <span class="hl-built_in">Send</span>&gt;&gt;();</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">inner</span> = scope.<span class="hl-title function_ invoke__">spawn</span>({</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">ctx</span> = Arc::<span class="hl-title function_ invoke__">clone</span>(&amp;ctx);</span>
<span class="line">    <span class="hl-keyword">move</span> || {</span>
<span class="line">      SharedContext::<span class="hl-title function_ invoke__">set</span>(Arc::<span class="hl-title function_ invoke__">clone</span>(&amp;ctx));</span>
<span class="line">      <span class="hl-keyword">for</span> <span class="hl-variable">f</span> <span class="hl-keyword">in</span> receiver {</span>
<span class="line">        <span class="hl-title function_ invoke__">f</span>(&amp;<span class="hl-keyword">mut</span> state);</span>
<span class="line">        <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">guard</span> = ctx.state.<span class="hl-title function_ invoke__">lock</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">        <span class="hl-built_in">assert_eq!</span>(*guard, State::Running);</span>
<span class="line">        *guard = State::Ready;</span>
<span class="line">        ctx.cv.<span class="hl-title function_ invoke__">notify_all</span>()</span>
<span class="line">      }</span>
<span class="line">    }</span>
<span class="line">  });</span>
<span class="line">  ManagedHandle { inner, ctx, sender }</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">impl</span>&lt;<span class="hl-symbol">&#x27;scope</span>, T&gt; ManagedHandle&lt;<span class="hl-symbol">&#x27;scope</span>, T&gt; {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">is_paused</span>(&amp;<span class="hl-keyword">self</span>) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">bool</span> {</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">guard</span> = <span class="hl-keyword">self</span>.ctx.state.<span class="hl-title function_ invoke__">lock</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">    *guard == State::Paused</span>
<span class="line">  }</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">unpause</span>(&amp;<span class="hl-keyword">self</span>) {</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">guard</span> = <span class="hl-keyword">self</span>.ctx.state.<span class="hl-title function_ invoke__">lock</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">    <span class="hl-built_in">assert_eq!</span>(*guard, State::Paused);</span>
<span class="line">    *guard = State::Running;</span>
<span class="line">    <span class="hl-keyword">self</span>.ctx.cv.<span class="hl-title function_ invoke__">notify_all</span>();</span>
<span class="line">    guard = <span class="hl-keyword">self</span></span>
<span class="line">      .ctx</span>
<span class="line">      .cv</span>
<span class="line">      .<span class="hl-title function_ invoke__">wait_while</span>(guard, |state| *state == State::Running)</span>
<span class="line">      .<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">  }</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">submit</span>&lt;F: <span class="hl-title function_ invoke__">FnOnce</span>(&amp;<span class="hl-keyword">mut</span> T) + <span class="hl-built_in">Send</span> + <span class="hl-symbol">&#x27;scope</span>&gt;(&amp;<span class="hl-keyword">self</span>, f: F) {</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">guard</span> = <span class="hl-keyword">self</span>.ctx.state.<span class="hl-title function_ invoke__">lock</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">    <span class="hl-built_in">assert_eq!</span>(*guard, State::Ready);</span>
<span class="line">    *guard = State::Running;</span>
<span class="line">    <span class="hl-keyword">self</span>.sender.<span class="hl-title function_ invoke__">send</span>(<span class="hl-type">Box</span>::<span class="hl-title function_ invoke__">new</span>(f)).<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">    guard = <span class="hl-keyword">self</span></span>
<span class="line">      .ctx</span>
<span class="line">      .cv</span>
<span class="line">      .<span class="hl-title function_ invoke__">wait_while</span>(guard, |state| *state == State::Running)</span>
<span class="line">      .<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">  }</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">join</span>(<span class="hl-keyword">self</span>) {</span>
<span class="line">    <span class="hl-keyword">while</span> <span class="hl-keyword">self</span>.<span class="hl-title function_ invoke__">is_paused</span>() {</span>
<span class="line">      <span class="hl-keyword">self</span>.<span class="hl-title function_ invoke__">unpause</span>();</span>
<span class="line">    }</span>
<span class="line">    <span class="hl-title function_ invoke__">drop</span>(<span class="hl-keyword">self</span>.sender);</span>
<span class="line">    <span class="hl-keyword">self</span>.inner.<span class="hl-title function_ invoke__">join</span>().<span class="hl-title function_ invoke__">unwrap</span>();</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>System under test, not-exactly-atomic counter:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">use</span> std::sync::atomic::Ordering::SeqCst;</span>
<span class="line"></span>
<span class="line"><span class="hl-meta">#[cfg(test)]</span></span>
<span class="line"><span class="hl-keyword">use</span> managed_thread::AtomicU32;</span>
<span class="line"><span class="hl-meta">#[cfg(not(test))]</span></span>
<span class="line"><span class="hl-keyword">use</span> std::sync::atomic::AtomicU32;</span>
<span class="line"></span>
<span class="line"><span class="hl-meta">#[derive(Default)]</span></span>
<span class="line"><span class="hl-keyword">pub</span> <span class="hl-keyword">struct</span> <span class="hl-title class_">Counter</span> {</span>
<span class="line">  value: AtomicU32,</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">Counter</span> {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">increment</span>(&amp;<span class="hl-keyword">self</span>) {</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">value</span> = <span class="hl-keyword">self</span>.value.<span class="hl-title function_ invoke__">load</span>(SeqCst);</span>
<span class="line">    <span class="hl-keyword">self</span>.value.<span class="hl-title function_ invoke__">store</span>(value + <span class="hl-number">1</span>, SeqCst);</span>
<span class="line">  }</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">get</span>(&amp;<span class="hl-keyword">self</span>) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">u32</span> {</span>
<span class="line">    <span class="hl-keyword">self</span>.value.<span class="hl-title function_ invoke__">load</span>(SeqCst)</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>And the test itself:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-meta">#[test]</span></span>
<span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">test_counter</span>() {</span>
<span class="line">  arbtest::<span class="hl-title function_ invoke__">arbtest</span>(|rng| {</span>
<span class="line">    eprintln!(<span class="hl-string">&quot;begin trace&quot;</span>);</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">counter</span> = Counter::<span class="hl-title function_ invoke__">default</span>();</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">counter_model</span>: <span class="hl-type">u32</span> = <span class="hl-number">0</span>;</span>
<span class="line"></span>
<span class="line">    std::thread::<span class="hl-title function_ invoke__">scope</span>(|scope| {</span>
<span class="line">      <span class="hl-keyword">let</span> <span class="hl-variable">t1</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>(scope, &amp;counter);</span>
<span class="line">      <span class="hl-keyword">let</span> <span class="hl-variable">t2</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>(scope, &amp;counter);</span>
<span class="line">      <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">threads</span> = [t1, t2];</span>
<span class="line"></span>
<span class="line">      <span class="hl-keyword">while</span> !rng.<span class="hl-title function_ invoke__">is_empty</span>() {</span>
<span class="line">        <span class="hl-title function_ invoke__">for</span> (tid, t) <span class="hl-keyword">in</span> threads.<span class="hl-title function_ invoke__">iter_mut</span>().<span class="hl-title function_ invoke__">enumerate</span>() {</span>
<span class="line">          <span class="hl-keyword">if</span> rng.<span class="hl-title function_ invoke__">arbitrary</span>()? {</span>
<span class="line">            <span class="hl-keyword">if</span> t.<span class="hl-title function_ invoke__">is_paused</span>() {</span>
<span class="line">              eprintln!(<span class="hl-string">&quot;{tid}: unpause&quot;</span>);</span>
<span class="line">              t.<span class="hl-title function_ invoke__">unpause</span>()</span>
<span class="line">            } <span class="hl-keyword">else</span> {</span>
<span class="line">              eprintln!(<span class="hl-string">&quot;{tid}: increment&quot;</span>);</span>
<span class="line">              t.<span class="hl-title function_ invoke__">submit</span>(|c| c.<span class="hl-title function_ invoke__">increment</span>());</span>
<span class="line">              counter_model += <span class="hl-number">1</span>;</span>
<span class="line">            }</span>
<span class="line">          }</span>
<span class="line">        }</span>
<span class="line">      }</span>
<span class="line"></span>
<span class="line">      <span class="hl-keyword">for</span> <span class="hl-variable">t</span> <span class="hl-keyword">in</span> threads {</span>
<span class="line">        t.<span class="hl-title function_ invoke__">join</span>();</span>
<span class="line">      }</span>
<span class="line">      <span class="hl-built_in">assert_eq!</span>(counter_model, counter.<span class="hl-title function_ invoke__">get</span>());</span>
<span class="line"></span>
<span class="line">      <span class="hl-title function_ invoke__">Ok</span>(())</span>
<span class="line">    })</span>
<span class="line">  });</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>Running it identifies a failure:</span></p>

<figure class="code-block">


<pre><code><span class="line">---- test_counter stdout ----</span>
<span class="line">begin trace</span>
<span class="line">0: increment</span>
<span class="line">1: increment</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">0: increment</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">1: increment</span>
<span class="line">0: unpause</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">thread 'test_counter' panicked at src/lib.rs:56:7:</span>
<span class="line">assertion `left == right` failed</span>
<span class="line">  left: 4</span>
<span class="line"> right: 3</span>
<span class="line"></span>
<span class="line">arbtest failed!</span>
<span class="line">    Seed: 0x4fd7ddff00000020</span></code></pre>

</figure>
<p><span>Which </span>&hellip;<span> is something we got like 5% into this article already, with normal threads! But there</span>&rsquo;<span>s</span>
<span>more to this failure. First, it is reproducible. If I specify the same seed, I get the </span><em><span>exact</span></em><span> same</span>
<span>interleaving:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-meta">#[test]</span></span>
<span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">test_counter</span>() {</span>
<span class="line">  arbtest::<span class="hl-title function_ invoke__">arbtest</span>(|rng| {</span>
<span class="line">    eprintln!(<span class="hl-string">&quot;begin trace&quot;</span>);</span>
<span class="line">    ...</span>
<span class="line">  })</span>
<span class="line hl-line">    .<span class="hl-title function_ invoke__">seed</span>(<span class="hl-number">0x71aafcd900000020</span>);</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>And this is completely machine independent! If </span><em><span>you</span></em><span> specify this seed, you</span>&rsquo;<span>ll get exact same</span>
<span>interleaving. So, if I am having trouble debugging this, I can DM you this hex in Zulip, and</span>
<span>you</span>&rsquo;<span>ll be able to help out!</span></p>
<p><span>But there</span>&rsquo;<span>s more </span>&mdash;<span> we don</span>&rsquo;<span>t need to debug this failure, we can minimize it!</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-meta">#[test]</span></span>
<span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">test_counter</span>() {</span>
<span class="line">  arbtest::<span class="hl-title function_ invoke__">arbtest</span>(|rng| {</span>
<span class="line">    eprintln!(<span class="hl-string">&quot;begin trace&quot;</span>);</span>
<span class="line">    ...</span>
<span class="line">  })</span>
<span class="line">    .<span class="hl-title function_ invoke__">seed</span>(<span class="hl-number">0x71aafcd900000020</span>)</span>
<span class="line hl-line">    .<span class="hl-title function_ invoke__">minimize</span>();</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>This gives me the following minimization trace:</span></p>

<figure class="code-block">


<pre><code><span class="line">begin trace</span>
<span class="line">0: increment</span>
<span class="line">1: increment</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">0: increment</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">1: increment</span>
<span class="line">0: unpause</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">seed 0x4fd7ddff00000020, seed size 32, search time 106.00ns</span>
<span class="line"></span>
<span class="line">begin trace</span>
<span class="line">0: increment</span>
<span class="line">1: increment</span>
<span class="line">0: unpause</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">1: unpause</span>
<span class="line">1: increment</span>
<span class="line">seed 0x540c0c1c00000010, seed size 16, search time 282.16µs</span>
<span class="line"></span>
<span class="line">begin trace</span>
<span class="line">0: increment</span>
<span class="line">1: increment</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">1: unpause</span>
<span class="line">1: unpause</span>
<span class="line">seed 0x084ca71200000008, seed size 8, search time 805.74µs</span>
<span class="line"></span>
<span class="line">begin trace</span>
<span class="line">0: increment</span>
<span class="line">1: increment</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">seed 0x5699b19400000004, seed size 4, search time 1.44ms</span>
<span class="line"></span>
<span class="line">begin trace</span>
<span class="line">0: increment</span>
<span class="line">1: increment</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">seed 0x4bb0ea5c00000002, seed size 2, search time 4.03ms</span>
<span class="line"></span>
<span class="line">begin trace</span>
<span class="line">0: increment</span>
<span class="line">1: increment</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">seed 0x9c2a13a600000001, seed size 1, search time 4.31ms</span>
<span class="line"></span>
<span class="line">minimized</span>
<span class="line">seed 0x9c2a13a600000001, seed size 1, search time 100.03ms</span></code></pre>

</figure>
<p><span>That is, we ended up with this tiny, minimal example:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-meta">#[test]</span></span>
<span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">test_counter</span>() {</span>
<span class="line">  arbtest::<span class="hl-title function_ invoke__">arbtest</span>(|rng| {</span>
<span class="line">    eprintln!(<span class="hl-string">&quot;begin trace&quot;</span>);</span>
<span class="line">    ...</span>
<span class="line">  })</span>
<span class="line hl-line">    .<span class="hl-title function_ invoke__">seed</span>(<span class="hl-number">0x9c2a13a600000001</span>);</span>
<span class="line">}</span></code></pre>

</figure>

<figure class="code-block">


<pre><code><span class="line">begin trace</span>
<span class="line">0: increment</span>
<span class="line">1: increment</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span></code></pre>

</figure>
<p><span>And </span><em><span>this</span></em><span> is how you properly test concurrent data structures.</span></p>
</section>
<section id="Postscript">

    <h2>
    <a href="#Postscript"><span>Postscript</span> </a>
    </h2>
<p><span>Of course, this is just a toy. But you can see some ways to extend it. For example, right now our</span>
<code>AtomicU32</code><span> just delegates to the real one. But what you </span><em><span>could</span></em><span> do instead is, for each atomic, to</span>
<span>maintain a set of values written and, on read, return an </span><em><span>arbitrary</span></em><span> written value consistent with a</span>
<span>weak memory model.</span></p>
<p><span>You could also be smarter with exploring interleavings. Instead of interleaving threads at random,</span>
<span>like we do here, you can try to apply model checking approaches and prove that you have considered</span>
<span>all meaningfully different interleavings.</span></p>
<p><span>Or you can apply the approach from </span><a href="https://matklad.github.io/2021/11/07/generate-all-the-things.html"><em><span>Generate All The</span>
<span>Things</span></em></a><span> and exhaustively</span>
<span>enumerate </span><em><span>all</span></em><span> interleavings for up to, say, five increments. In fact, why don</span>&rsquo;<span>t we just do this?</span></p>
<p><code class="display">$ cargo add exhaustigen</code></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-meta">#[test]</span></span>
<span class="line"><span class="hl-keyword">fn</span> <span class="hl-title function_">exhaustytest</span>() {</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">g</span> = exhaustigen::Gen::<span class="hl-title function_ invoke__">new</span>();</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">interleavings_count</span> = <span class="hl-number">0</span>;</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">while</span> !g.<span class="hl-title function_ invoke__">done</span>() {</span>
<span class="line">    interleavings_count += <span class="hl-number">1</span>;</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">counter</span> = Counter::<span class="hl-title function_ invoke__">default</span>();</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-keyword">mut </span><span class="hl-variable">counter_model</span>: <span class="hl-type">u32</span> = <span class="hl-number">0</span>;</span>
<span class="line"></span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">increment_count</span> = g.<span class="hl-title function_ invoke__">gen</span>(<span class="hl-number">5</span>) <span class="hl-keyword">as</span> <span class="hl-type">u32</span>;</span>
<span class="line">    std::thread::<span class="hl-title function_ invoke__">scope</span>(|scope| {</span>
<span class="line">      <span class="hl-keyword">let</span> <span class="hl-variable">t1</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>(scope, &amp;counter);</span>
<span class="line">      <span class="hl-keyword">let</span> <span class="hl-variable">t2</span> = managed_thread::<span class="hl-title function_ invoke__">spawn</span>(scope, &amp;counter);</span>
<span class="line"></span>
<span class="line">      <span class="hl-symbol">&#x27;outer</span>: <span class="hl-keyword">while</span> t1.<span class="hl-title function_ invoke__">is_paused</span>()</span>
<span class="line">        || t2.<span class="hl-title function_ invoke__">is_paused</span>()</span>
<span class="line">        || counter_model &lt; increment_count</span>
<span class="line">      {</span>
<span class="line">        <span class="hl-keyword">for</span> <span class="hl-variable">t</span> <span class="hl-keyword">in</span> [&amp;t1, &amp;t2] {</span>
<span class="line">          <span class="hl-keyword">if</span> g.<span class="hl-title function_ invoke__">flip</span>() {</span>
<span class="line">            <span class="hl-keyword">if</span> t.<span class="hl-title function_ invoke__">is_paused</span>() {</span>
<span class="line">              t.<span class="hl-title function_ invoke__">unpause</span>();</span>
<span class="line">              <span class="hl-keyword">continue</span> <span class="hl-symbol">&#x27;outer</span>;</span>
<span class="line">            }</span>
<span class="line">            <span class="hl-keyword">if</span> counter_model &lt; increment_count {</span>
<span class="line">              t.<span class="hl-title function_ invoke__">submit</span>(|c| c.<span class="hl-title function_ invoke__">increment</span>());</span>
<span class="line">              counter_model += <span class="hl-number">1</span>;</span>
<span class="line">              <span class="hl-keyword">continue</span> <span class="hl-symbol">&#x27;outer</span>;</span>
<span class="line">            }</span>
<span class="line">          }</span>
<span class="line">        }</span>
<span class="line">        <span class="hl-keyword">return</span> <span class="hl-keyword">for</span> <span class="hl-variable">t</span> <span class="hl-keyword">in</span> [t1, t2] {</span>
<span class="line">          t.<span class="hl-title function_ invoke__">join</span>()</span>
<span class="line">        };</span>
<span class="line">      }</span>
<span class="line"></span>
<span class="line">      <span class="hl-built_in">assert_eq!</span>(counter_model, counter.<span class="hl-title function_ invoke__">get</span>());</span>
<span class="line">    });</span>
<span class="line">  }</span>
<span class="line">  eprintln!(<span class="hl-string">&quot;interleavings_count = {:?}&quot;</span>, interleavings_count);</span>
<span class="line">}</span></code></pre>

</figure>
<p><span>The shape of the test is more or less the same, except that we need to make sure that there are no</span>
&ldquo;<span>dummy</span>&rdquo;<span> iterations, and that we always either unpause a thread or submit an increment.</span></p>
<p><span>It finds the same bug, naturally:</span></p>

<figure class="code-block">


<pre><code><span class="line">thread 'exhaustytest' panicked at src/lib.rs:103:7:</span>
<span class="line">assertion `left == right` failed</span>
<span class="line">  left: 2</span>
<span class="line"> right: 1</span></code></pre>

</figure>
<p><span>But the cool thing is, if we fix the issue by using atomic increment, </span>&hellip;</p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">AtomicU32</span> {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">fetch_add</span>(</span>
<span class="line">    &amp;<span class="hl-keyword">self</span>,</span>
<span class="line">    value: <span class="hl-type">u32</span>,</span>
<span class="line">    ordering: Ordering,</span>
<span class="line">  ) <span class="hl-punctuation">-&gt;</span> <span class="hl-type">u32</span> {</span>
<span class="line">    <span class="hl-title function_ invoke__">pause</span>();</span>
<span class="line">    <span class="hl-keyword">let</span> <span class="hl-variable">result</span> = <span class="hl-keyword">self</span>.inner.<span class="hl-title function_ invoke__">fetch_add</span>(value, ordering);</span>
<span class="line">    <span class="hl-title function_ invoke__">pause</span>();</span>
<span class="line">    result</span>
<span class="line">  }</span>
<span class="line">}</span>
<span class="line"></span>
<span class="line"><span class="hl-keyword">impl</span> <span class="hl-title class_">Counter</span> {</span>
<span class="line">  <span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span> <span class="hl-title function_">increment</span>(&amp;<span class="hl-keyword">self</span>) {</span>
<span class="line">    <span class="hl-keyword">self</span>.value.<span class="hl-title function_ invoke__">fetch_add</span>(<span class="hl-number">1</span>, SeqCst);</span>
<span class="line">  }</span>
<span class="line">}</span></code></pre>

</figure>
<p>&hellip;<span> we can get a rather specific correctness statements out of our test, that </span><em><span>any</span></em><span> sequence of at</span>
<span>most five increments is correct:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-title function_">$</span> t cargo t -r -- exhaustytest --nocapture</span>
<span class="line"><span class="hl-output">running 1 test</span></span>
<span class="line"><span class="hl-output">all 81133 interleavings are fine!</span></span>
<span class="line"><span class="hl-output">test exhaustytest ... ok</span></span>
<span class="line"><span class="hl-output"></span></span>
<span class="line"><span class="hl-output">real 8.65s</span></span>
<span class="line"><span class="hl-output">cpu  8.16s (2.22s user + 5.94s sys)</span></span>
<span class="line"><span class="hl-output">rss  63.91mb</span></span></code></pre>

</figure>
<p><span>And the last small thing. Recall that our PBT minimized the first sequence it found </span>&hellip;<span>:</span></p>

<figure class="code-block">


<pre><code><span class="line">begin trace</span>
<span class="line">0: increment</span>
<span class="line">1: increment</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">0: increment</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">1: increment</span>
<span class="line">0: unpause</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">0: unpause</span>
<span class="line">thread 'test_counter' panicked at src/lib.rs:56:7:</span>
<span class="line">assertion `left == right` failed</span>
<span class="line">  left: 4</span>
<span class="line"> right: 3</span>
<span class="line"></span>
<span class="line">arbtest failed!</span>
<span class="line">    Seed: 0x4fd7ddff00000020</span></code></pre>

</figure>
<p>&hellip;<span> down to just</span></p>

<figure class="code-block">


<pre><code><span class="line">begin trace</span>
<span class="line">0: increment</span>
<span class="line">1: increment</span>
<span class="line">0: unpause</span>
<span class="line">1: unpause</span>
<span class="line">thread 'test_counter' panicked at src/lib.rs:57:7:</span>
<span class="line">assertion `left == right` failed</span>
<span class="line">  left: 2</span>
<span class="line"> right: 1</span>
<span class="line"></span>
<span class="line">arbtest failed!</span>
<span class="line">    Seed: 0x9c2a13a600000001</span></code></pre>

</figure>
<p><span>But we never implemented shrinking! How is this possible? Well, strictly speaking, this is out of</span>
<span>scope for this post. And I</span>&rsquo;<span>ve already described this</span>
<a href="https://tigerbeetle.com/blog/2023-03-28-random-fuzzy-thoughts"><span>elsewhere</span></a><span>. And, at 32k, this is the</span>
<span>third-longest post on this blog. And it</span>&rsquo;<span>s 3AM here in Lisbon right now. But of course I</span>&rsquo;<span>ll explain!</span></p>
<p><span>The trick is the simplified </span><a href="https://hypothesis.works/articles/compositional-shrinking/"><span>hypothesis</span>
<span>approach</span></a><span>. The</span>
<a href="https://docs.rs/arbtest/latest/arbtest/"><span>arbtest</span></a><span> PBT library we use in this post is based on a</span>
<span>familiar interface of a PRNG:</span></p>

<figure class="code-block">


<pre><code><span class="line">arbtest::<span class="hl-title function_ invoke__">arbtest</span>(|rng| {</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">random_int</span>: <span class="hl-type">usize</span> = rng.<span class="hl-title function_ invoke__">int_in_range</span>(<span class="hl-number">0</span>..=<span class="hl-number">100</span>)?;</span>
<span class="line">  <span class="hl-keyword">let</span> <span class="hl-variable">random_bool</span>: <span class="hl-type">bool</span> = rng.<span class="hl-title function_ invoke__">arbitrary</span>()?;</span>
<span class="line">  <span class="hl-title function_ invoke__">Ok</span>(())</span>
<span class="line">});</span></code></pre>

</figure>
<p><span>But there</span>&rsquo;<span>s a twist! This is a </span><em><span>finite</span></em><span> PRNG. So, if you ask it to flip a coin it can give you</span>
<span>heads. And next time it might give you tails. But if you continue asking it for more, at some point</span>
<span>it</span>&rsquo;<span>ll give you </span><span class="display"><code>Err(OutOfEntropy)</code><span>.</span></span></p>
<p><span>That</span>&rsquo;<span>s why all these </span><code>?</code><span> and the outer loop of</span>
<span class="display"><code>while !rng.is_empty() {</code><span>.</span></span></p>
<p><span>In other words, as soon as the test runs out of entropy, it short-circuits and completes. And that</span>
<span>means that by reducing the amount of entropy available the test becomes shorter, and this works</span>
<span>irrespective of how complex is the logic inside the test!</span></p>
<p><span>And </span>&ldquo;<span>entropy</span>&rdquo;<span> is a big scary word here, what actually happens is that the PRNG is just an </span><code>&amp;mut
&amp;[u8]</code><span> inside. That is, a slice of random bytes, which is shortened every time you ask for a random</span>
<span>number. And the shorter the initial slice, the simpler the test gets. Minimization can be this</span>
<span>simple!</span></p>
<p><span>You can find source code for this article at</span>
<a href="https://github.com/matklad/properly-concurrent" class="display url">https://github.com/matklad/properly-concurrent</a></p>
</section>
]]></content>
</entry>

<entry>
<title type="text">Regular, Recursive, Restricted</title>
<link href="https://matklad.github.io/2024/06/04/regular-recursive-restricted.html" rel="alternate" type="text/html" title="Regular, Recursive, Restricted" />
<published>2024-06-04T00:00:00+00:00</published>
<updated>2024-06-04T00:00:00+00:00</updated>
<id>https://matklad.github.io/2024/06/04/regular-recursive-restricted</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[A post/question about formal grammars, wherein I search for a good formalism for describing infix
expressions.]]></summary>
<content type="html" xml:base="https://matklad.github.io/2024/06/04/regular-recursive-restricted.html"><![CDATA[
<h1><span>Regular, Recursive, Restricted</span> <time class="meta" datetime="2024-06-04">Jun 4, 2024</time></h1>
<p><span>A post/question about formal grammars, wherein I search for a good formalism for describing infix</span>
<span>expressions.</span></p>
<p><span>Problem statement: it</span>&rsquo;<span>s hard to describe arithmetic expressions in a way that:</span></p>
<ul>
<li>
<span>declaratively captures the overall shape of expression, and</span>
</li>
<li>
<span>has a clear precedence semantics</span>
</li>
</ul>
<p><span>Let</span>&rsquo;<span>s start with the following grammar for arithmetic expressions:</span></p>

<figure class="code-block">


<pre><code><span class="line">Expr =</span>
<span class="line">    'number'</span>
<span class="line">  | '(' Expr ')'</span>
<span class="line">  | Expr '+' Expr</span>
<span class="line">  | Expr '*' Expr</span></code></pre>

</figure>
<p><span>It is definitely declarative and obvious. But it is ambiguous </span>&mdash;<span> it doesn</span>&rsquo;<span>t tell whether </span><code>*</code><span> or </span><code>+</code>
<span>binds tighter, and their associativity. You </span><em><span>can</span></em><span> express those properties directly in the grammar:</span></p>

<figure class="code-block">


<pre><code><span class="line">Expr =</span>
<span class="line">    Factor</span>
<span class="line">  | Expr '+' Factor</span>
<span class="line"></span>
<span class="line">Factor =</span>
<span class="line">    Atom</span>
<span class="line">  | Factor '*' Atom</span>
<span class="line"></span>
<span class="line">Atom = 'number' | '(' Expr ')'</span></code></pre>

</figure>
<p><span>But at this point we lose decorativeness. The way my brain parses the above grammar is by pattern</span>
<span>matching it as a grammar for infix expressions and folding it back to the initial compressed form,</span>
<em><span>not</span></em><span> by reading the grammar rules as written.</span></p>
<p><span>To go in another direction, you can define ambiguity away and get parsing expression grammars:</span></p>

<figure class="code-block">


<pre><code><span class="line">Exp =</span>
<span class="line">    Sum</span>
<span class="line">  / Product</span>
<span class="line">  / Atom</span>
<span class="line"></span>
<span class="line">Sum     = Expr (('+' / '-') Expr)+</span>
<span class="line">Product = Expr (('*' / '/') Expr)+</span>
<span class="line"></span>
<span class="line">Atom = 'number' | '(' Expr ')'</span></code></pre>

</figure>
<p><span>This captures precedence </span><em><span>mostly</span></em><span> declaratively: we first match </span><code>Sum</code><span>, and, failing that, match</span>
<code>Product</code><span>. But the clarity of semantics is lost </span>&mdash;<span> PEGs are never ambiguous by virtue of always</span>
<span>picking the first alternative, so it</span>&rsquo;<span>s too easy to introduce an unintended ambiguity.</span></p>
<p><span>Can we have both? Clarity with respect to tree shape and clarity with respect to ambiguity?</span></p>
<p><span>Let me present a formalism that, I think, ticks both boxes for the toy example and pose a question</span>
<span>of whether it generalizes.</span></p>
<hr>
<p><span>Running example:</span></p>

<figure class="code-block">


<pre><code><span class="line">E =</span>
<span class="line">    'number'</span>
<span class="line">  | '(' E ')'</span>
<span class="line">  | E '+' E</span></code></pre>

</figure>
<p><span>As a grammar for strings, it is ambiguous. There are two parse trees for </span><code>1 + 2 + 3</code><span> </span>&mdash;<span> the</span>
&ldquo;<span>correct</span>&rdquo;<span> one </span><code>(1 + 2) + 3</code><span>, and the alternative: </span><code>1 + (2 + 3)</code><span>.</span></p>
<p><span>Instead, lets see it as a grammar for trees instead. Specifically, trees where:</span></p>
<ul>
<li>
<span>Leaves are labeled with </span><code>'number'</code><span>, </span><code>'+'</code><span>, or </span><code>'*'</code><span>.</span>
</li>
<li>
<span>Interior nodes are labeled with </span><code>E</code><span>.</span>
</li>
<li>
<span>For each interior node, the string formed by labels of its </span><em><span>direct</span></em><span> children conforms to the</span>
<span>specified regular expression.</span>
</li>
</ul>
<p><span>For trees, this is a perfectly fine grammar! Given a labeled tree, its trivial to check whether it</span>
<span>matches the grammar: for each node, you can directly match the regular expression. There</span>&rsquo;<span>s also no</span>
<span>meaningful ambiguity </span>&mdash;<span> while arbitrary regular expressions can be ambiguous (</span><code>aa | a*</code><span>), this</span>
<span>doesn</span>&rsquo;<span>t really come up as harmful in practice all that often, and, in any case, it</span>&rsquo;<span>s easy to check</span>
<span>that any two regular alternatives are disjoint (intersect the two automata, minimize the result,</span>
<span>check if it is empty).</span></p>
<p><span>As a grammar for trees, it has the following property: there are two distinct trees which</span>
<span>nevertheless share the same sequence of leaves:</span></p>

<figure class="code-block">


<pre><code><span class="line">        E                  E</span>
<span class="line">        o                  o</span>
<span class="line">      / | \              / | \</span>
<span class="line">     E '+' E            E '+' E</span>
<span class="line">     o     |            |     o</span>
<span class="line">   / | \  '3'          '1'  / | \</span>
<span class="line">  E '+' E                  E '+' E</span>
<span class="line">  |     |                  |     |</span>
<span class="line"> '1'   '2'                '2'   '3'</span></code></pre>

</figure>
<p><span>So let</span>&rsquo;<span>s restrict the set of trees, in the most straightforward manner, by adding some inequalities:</span></p>

<figure class="code-block">


<pre><code><span class="line">E =</span>
<span class="line">    'number'</span>
<span class="line">  | '(' E ')'</span>
<span class="line">  | E '+' E</span>
<span class="line"></span>
<span class="line">E !=</span>
<span class="line">    E '+' [E '+' E]</span></code></pre>

</figure>
<p><span>Here, square brackets denote a child. </span><code>E '+' [E '+' E]</code><span> is a plus node whose right child is also a</span>
<span>plus node. Checking whether a tree conform to this modified set of rules is easy as negative rules</span>
<span>are also just regular expressions. Well, I think you need some fiddling here, as, as written, a</span>
<span>negative rule matches two different levels of the tree, but you can flatten both the rule and the</span>
<span>actual tree to the grandchildren level by enclosing children in parenthesis. Let me show an example:</span></p>
<p><span>We want to match this node:</span></p>

<figure class="code-block">


<pre><code><span class="line">    E</span>
<span class="line">    o</span>
<span class="line">  / | \</span>
<span class="line"> E '+' E</span>
<span class="line"> |     o</span>
<span class="line">'1'  / | \</span>
<span class="line">    E '+' E</span></code></pre>

</figure>
<p><span>against this rule concerning children and grand children:</span></p>

<figure class="code-block">


<pre><code><span class="line">E '+' [E '+' E]</span></code></pre>

</figure>
<p><span>We write the list of children and grandchidren of the node, while adding extra </span><code>[]</code><span>, to get this</span>
<span>string:</span></p>

<figure class="code-block">


<pre><code><span class="line">['1'] '+' [E '+' E]</span></code></pre>

</figure>
<p><span>And in the rule we replace top-level non-terminals with </span><code>[.*]</code><span>, to get this regular expression:</span></p>

<figure class="code-block">


<pre><code><span class="line">[.*] '+' [E '+' E]</span></code></pre>

</figure>
<p><span>Now we can match the string against a regex, get a mach, and rule out the tree (remember, this is</span>
<code>!=</code><span>).</span></p>
<p><span>So here it is, a perfectly functional mathematical animal: recursive restricted regular expression:</span></p>
<ul>
<li>
<span>A set of non-terminals </span><code>N</code><span> (denoted with </span><code>TitleCase</code><span> names)</span>
</li>
<li>
<span>A set of terminals </span><code>T</code><span> (denoted with </span><code>'quoted'</code><span> names)</span>
</li>
<li>
<span>A generating mapping from non-terminals </span><code>N</code><span> to regular expressions over </span><code>N ∪ T</code><span> alphabet</span>
</li>
<li>
<span>A restricting mapping from non-terminals </span><code>N</code><span> to regular expressions over </span><code>N ∪ T ∪ {], [}</code><span> (that is</span>
<span>regular expressions with square brackets to denote children)</span>
</li>
</ul>
<p><span>This construction denotes a set of labeled trees, where interior nodes are labeled with </span><code>N</code><span>, leaves</span>
<span>are labeled with </span><code>T</code><span> and for each interior node</span></p>
<ul>
<li>
<span>its children match the corresponding generating regular expression</span>
</li>
<li>
<span>its grandchildren do not match the corresponding restricting regular expression</span>
</li>
</ul>
<p><span>And the main question one would have, if confronted with a specimen, is </span>&ldquo;<span>is it ambiguous?</span>&rdquo;<span> That is,</span>
<span>are there two trees in the set which have the same sequence of leaves?</span></p>
<p><span>Let</span>&rsquo;<span>s look at an example:</span></p>

<figure class="code-block">


<pre><code><span class="line">Expr =</span>
<span class="line">    'number'</span>
<span class="line">  | '(' Expr ')'</span>
<span class="line">  | Expr '+' Expr</span>
<span class="line">  | Expr '*' Expr</span>
<span class="line"></span>
<span class="line">Expr !=</span>
<span class="line">             Expr '+' [Expr '+' Expr]</span>
<span class="line">|            Expr '*' [Expr '*' Expr]</span>
<span class="line">|            Expr '*' [Expr '+' Expr]</span>
<span class="line">| [Expr '+' Expr] '*' Expr</span></code></pre>

</figure>
<p><span>It looks unambiguous to me! And I am pretty sure that I can prove, by hand, that it is in fact</span>
<span>unambiguous (well, I might discover that I miss a couple of restrictions in process, but it feels</span>
<span>like it should work in principle). The question is, can a computer take an arbitrary recursive</span>
<span>restricted regular expression and tell me that its unambiguous, or, failing that, provide a</span>
<span>counter-example?</span></p>
<p><span>In the general case, the answer is no </span>&mdash;<span> this is at least as expressive as CFG, and ambiguity of</span>
<span>arbitrary CFG is undecidable. But perhaps there</span>&rsquo;<span>s some reasonable set of restrictions under which it</span>
<span>is in fact possible to prove the absence of ambiguity?</span></p>
]]></content>
</entry>

<entry>
<title type="text">Basic Things</title>
<link href="https://matklad.github.io/2024/03/22/basic-things.html" rel="alternate" type="text/html" title="Basic Things" />
<published>2024-03-22T00:00:00+00:00</published>
<updated>2024-03-22T00:00:00+00:00</updated>
<id>https://matklad.github.io/2024/03/22/basic-things</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[After working on the initial stages of several largish projects, I accumulated a list of things that
share the following three properties:]]></summary>
<content type="html" xml:base="https://matklad.github.io/2024/03/22/basic-things.html"><![CDATA[
<h1><span>Basic Things</span> <time class="meta" datetime="2024-03-22">Mar 22, 2024</time></h1>
<p><span>After working on the initial stages of several largish projects, I accumulated a list of things that</span>
<span>share the following three properties:</span></p>
<ul>
<li>
<span>they are irrelevant while the project is small,</span>
</li>
<li>
<span>they are a productivity multiplier when the project is large,</span>
</li>
<li>
<span>they are much harder to introduce down the line.</span>
</li>
</ul>
<p><span>Here</span>&rsquo;<span>s the list:</span></p>
<section id="READMEs">

    <h2>
    <a href="#READMEs"><span>READMEs</span> </a>
    </h2>
<p><span>A project should have a </span><em><span>short</span></em><span> one-page readme that is mostly links to more topical documentation.</span>
<span>The two most important links are the user docs and the dev docs.</span></p>
<p><span>A common failure is a readme growing haphazardly by accretion, such that it is neither a good</span>
<span>landing page, nor a source of comprehensive docs on any particular topic. It is hard to refactor</span>
<span>such an unstructured readme later. The information is valuable, if disorganized, but there</span>
<span>isn</span>&rsquo;<span>t any better place to move it to.</span></p>
</section>
<section id="Developer-Docs">

    <h2>
    <a href="#Developer-Docs"><span>Developer Docs</span> </a>
    </h2>
<p><span>For developers, you generally want to have a docs folder in the repository. The docs folder should</span>
<em><span>also</span></em><span> contain a short landing page describing the structure of the documentation. This structure</span>
<span>should allow for both a small number of high quality curated documents, and a large number of ad-hoc</span>
<span>append-only notes on any particular topic. For example, </span><code>docs/README.md</code><span> could point to carefully</span>
<span>crafted</span>
<a href="https://matklad.github.io/2021/02/06/ARCHITECTURE.md.html"><code>ARCHITECTURE.md</code></a>
<span>and </span><code>CONTRIBUTING.md</code><span>, which describe high level code and social</span>
<span>architectures, and explicitly say that everything else in the </span><code>docs/</code><span> folder is a set of unorganized</span>
<span>topical guides.</span></p>
<p><span>Common failure modes here:</span></p>
<ol type="a">
<li>
<p><span>There</span>&rsquo;<span>s no place where to put new developer documentation at all. As a result, no docs are</span>
<span>getting written, and, by the time you do need docs, the knowledge is lost.</span></p>
</li>
<li>
<p><span>There</span>&rsquo;<span>s only highly  structured, carefully reviewed developer documentation. Contributing docs</span>
<span>requires a lot of efforts, and many small things go undocumented.</span></p>
</li>
<li>
<p><span>There</span>&rsquo;<span>s only unstructured append-only pile of isolated documents. Things are </span><em><span>mostly</span></em><span> documented,</span>
<span>often two or three times, but any new team member has to do the wheat from the chaff thing anew.</span></p>
</li>
</ol>
</section>
<section id="Users-Website">

    <h2>
    <a href="#Users-Website"><span>Users Website</span> </a>
    </h2>
<p><span>Most project can benefit from a dedicated website targeted at the users. You want to have website</span>
<span>ready when there are few-to-no users: usage compounds over time, so, if you find yourself with a</span>
<span>significant number of users and no web </span>&ldquo;<span>face</span>&rdquo;<span>, you</span>&rsquo;<span>ve lost quite a bit of value already!</span></p>
<p><span>Some other failure modes here:</span></p>
<ol type="a">
<li>
<p><span>A different team manages the website. This prevents project developers from directly contributing</span>
<span>improvements, and may lead to divergence between the docs and the shipped product.</span></p>
</li>
<li>
<p><span>Today</span>&rsquo;<span>s web stacks gravitate towards infinite complexity. It</span>&rsquo;<span>s all too natural to pick an </span>&ldquo;<span>easy</span>&rdquo;
<span>heavy framework at the start, and then get yourself into npm</span>&rsquo;<span>s bog. Website is about content, and</span>
<span>content has gravity. Whatever markup language dialect you choose at the beginning is going to</span>
<span>stay with for some time. Do carefully consider the choice of your web stack.</span></p>
</li>
<li>
<p><span>Saying that which isn</span>&rsquo;<span>t quite done yet. Don</span>&rsquo;<span>t overpromise, it</span>&rsquo;<span>s much easier to say more later</span>
<span>than to take back your words, and humbleness might be a good marketing. Consider if you are in a</span>
<span>domain where engineering credibility travel faster than buzz words. But this is situational. More</span>
<span>general advice would be that marketing also compounds over time, so it pays off to be deliberate</span>
<span>about your image from the start.</span></p>
</li>
</ol>
</section>
<section id="Internal-Website">

    <h2>
    <a href="#Internal-Website"><span>Internal Website</span> </a>
    </h2>
<p><span>This is more situational, but consider if, in addition to public-facing website, you also need an</span>
<span>internal, engineering-facing one. At some point you</span>&rsquo;<span>ll probably need a bit more interactivity than</span>
<span>what</span>&rsquo;<span>s available in a </span><code>README.md</code><span> </span>&mdash;<span> perhaps you need a place to display code-related metrics like</span>
<span>coverage or some javascript to compute release rotation. Having a place on the web where a</span>
<span>contributor can place something they need right now without much red tape is nice!</span></p>
<p><span>This is a recurring theme </span>&mdash;<span> you should be organized, you should not be organized. </span><em><span>Some</span></em><span> things</span>
<span>have large fan-out and should be guarded with careful review. </span><em><span>Other</span></em><span> things benefit from just being</span>
<span>there and a lightweight process. You need to create places for both kinds of things, and a clear</span>
<span>decision rule about what goes where.</span></p>
<p><span>For internal website, you</span>&rsquo;<span>ll probably need some kind of data store as well. If you want to track</span>
<span>binary size across commits, </span><em><span>something</span></em><span> needs to map commit hashes to (lets be optimistic)</span>
<span>kilobytes! I don</span>&rsquo;<span>t know a good solution here. I use a JSON file in a github repository for similar</span>
<span>purposes.</span></p>
</section>
<section id="Process-Docs">

    <h2>
    <a href="#Process-Docs"><span>Process Docs</span> </a>
    </h2>
<p><span>There are many possible ways to get some code into the main branch. Pick one, and spell it out in</span>
<span>an </span><code>.md</code><span> file explicitly:</span></p>
<ul>
<li>
<p><span>Are feature branches pushed to the central repository, or is anyone works off their fork? I find</span>
<span>forks work better in general as they automatically namespace everyone</span>&rsquo;<span>s branches, and put team</span>
<span>members and external contributors on equal footing.</span></p>
</li>
<li>
<p><span>If the repository is shared, what is the naming convention for branches? I prefix mine with</span>
<code>matklad/</code><span>.</span></p>
</li>
<li>
<p><span>You use </span><a href="https://graydon2.dreamwidth.org/1597.html"><span>not rocket-science rule</span></a><span> (more on this later :).</span></p>
</li>
<li>
<p><span>Who should do code review of a particular PR? A single person, to avoid bystander effect and to</span>
<span>reduce notification fatigue. The reviewer is picked by the author of PR, as that</span>&rsquo;<span>s a stable</span>
<span>equilibrium in a high-trust team and cuts red tape.</span></p>
</li>
<li>
<p><span>How the reviewer knows that they need to review code? On GitHub, you want to </span><em><span>assign</span></em><span> rather than</span>
<em><span>request</span></em><span> a review. Assign is level-triggered </span>&mdash;<span> it won</span>&rsquo;<span>t go away until the PR is merged, and it</span>
<span>becomes the responsibility of the reviewer to help the PR along until it is merged (</span><em><span>request</span>
<span>review</span></em><span> is still useful to poke the assignee after a round of feedback&amp;changes). More generally,</span>
<span>code review is the highest priority task </span>&mdash;<span> there</span>&rsquo;<span>s no reason to work on new code</span>
<span>if there</span>&rsquo;<span>s already some finished code which is just blocked on your review.</span></p>
</li>
<li>
<p><span>What is the purpose of review? Reviewing for correctness, for single voice, for idioms, for</span>
<span>knowledge sharing, for high-level architecture are choices! Explicitly spell out what makes most</span>
<span>sense in the context of your project.</span></p>
</li>
<li>
<p><span>Meta process docs: positively encourage contributing process documentation itself.</span></p>
</li>
</ul>
</section>
<section id="Style">

    <h2>
    <a href="#Style"><span>Style</span> </a>
    </h2>
<p><span>Speaking about meta process, style guide is where it is most practically valuable. Make sure that</span>
<span>most stylistic comments during code reviews are immediately codified in the project-specific style</span>
<span>document. New contributors should learn project</span>&rsquo;<span>s voice not through a hundred repetitive comments on</span>
<span>PRs, but through a dozen links to specific items of the style guide.</span></p>
<p><span>Do you even need a project-specific style guide? I think you do </span>&mdash;<span> cutting down mental energy for</span>
<span>trivial decisions is helpful. If you need a result variable, and half of the functions call it </span><code>res</code>
<span>and another half of the functions call it </span><code>result</code><span>, making this choice is just distracting.</span></p>
<p><span>Project-specific naming conventions is one of the more useful thing to place in the style guide.</span></p>
<p><span>Optimize style guide for extensibility. Uplifting a comment from a code review to the style guide</span>
<span>should not require much work.</span></p>
<p><span>Ensure that there</span>&rsquo;<span>s a style tzar </span>&mdash;<span> building consensus around </span><em><span>specific</span></em><span> style choices is very</span>
<span>hard, better to delegate the entire responsibility to one person who can make good enough choices.</span>
<span>Style usually is not about what</span>&rsquo;<span>s better, it</span>&rsquo;<span>s about removing needless options in a semi-arbitrary</span>
<span>ways.</span></p>
</section>
<section id="Git">

    <h2>
    <a href="#Git"><span>Git</span> </a>
    </h2>
<p><span>Document stylistic details pertaining to git. If project uses </span><code>area:</code><span> prefixes for commits, spell</span>
<span>out an explicit list of such prefixes.</span></p>
<p><span>Consider documenting acceptable line length for the summary line. Git man page boldly declares that</span>
<span>a summary should be under 50 characters, but that is just plain false. Even in the kernel, most</span>
<span>summaries are somewhere between 50 and 80 characters.</span></p>
<p><span>Definitely explicitly forbid adding large files to git. Repository size increases monotonically,</span>
<code>git clone</code><span> time is important.</span></p>
<p><span>Document merge-vs-rebase thing. My preferred answer is:</span></p>
<ul>
<li>
<span>A unit of change is a pull request, which might contain several commits</span>
</li>
<li>
<span>Merge commit for the pull request is what is being tested</span>
</li>
<li>
<span>The main branch contains only merge commits</span>
</li>
<li>
<span>Conversely, </span><em><span>only</span></em><span> the main branch contains merge commits, pull requests themselves are always</span>
<span>rebased.</span>
</li>
</ul>
<p><span>Forbidding large files in the repo is a good policy, but it</span>&rsquo;<span>s hard to follow. Over the lifetime of</span>
<span>the project, someone somewhere will sneakily add and revert a megabyte of generated protobufs, and</span>
<span>that will fly under code review radar.</span></p>
<p><span>This brings us to the most basic thing of them all:</span></p>
</section>
<section id="Not-Rocket-Science-Rule">

    <h2>
    <a href="#Not-Rocket-Science-Rule"><span>Not Rocket Science Rule</span> </a>
    </h2>
<p><span>Maintain a well-defined set of automated checks that pass on the main branch at all times. If you</span>
<span>don</span>&rsquo;<span>t want large blobs in git repository, write a test rejecting large git objects and run that</span>
<span>right before updating the main branch. No merge commits on feature branches? Write a test which</span>
<span>fails with a pageful of Git self-help if one is detected. Want to wrap </span><code>.md</code><span> at 80 columns? Write a</span>
<span>test :)</span></p>
<p><span>It is perhaps worth you while to re-read the original post:</span>
<a href="https://graydon2.dreamwidth.org/1597.html" class="display url">https://graydon2.dreamwidth.org/1597.html</a></p>
<p><a href="https://matklad.github.io/2024/01/03/of-rats-and-ratchets.html"><span>This mindset of monotonically growing set of properties</span></a>
<span>that are true about the codebase is </span><em><span>incredibly</span></em><span> powerful. You start seeing code as temporary, fluid</span>
<span>thing that can always be changed relatively cheaply, and the accumulated set of automated tests as</span>
<span>the real value of the project.</span></p>
<p><span>Another second order effect is that NRSR puts a pressure to optimize your build and test</span>
<span>infrastructure. If you don</span>&rsquo;<span>t have an option to merge the code when an unrelated flaky test fails,</span>
<span>you won</span>&rsquo;<span>t have flaky tests.</span></p>
<p><span>A common anti-pattern here is that a project grows a set of semi-checks </span>&mdash;<span> tests that exists, but</span>
<span>are not 100% reliable, and thus are not exercised by the CI routinely. And that creates ambiguity</span>
&mdash;<span> are tests failing due to a regression which should be fixed, or were they never reliable, and</span>
<span>just test a property that isn</span>&rsquo;<span>t actually essential for functioning of the project? This fuzziness</span>
<span>compounds over time. If a check isn</span>&rsquo;<span>t reliable enough to be part of NRSR CI gate, it isn</span>&rsquo;<span>t actually</span>
<span>a check you care about, and should be removed.</span></p>
<p><span>But to do NRSR, you need to build &amp; CI your code first:</span></p>
</section>
<section id="Build-CI">

    <h2>
    <a href="#Build-CI"><span>Build &amp; CI</span> </a>
    </h2>
<p><span>This is a complex topic. Let</span>&rsquo;<span>s start with the basics: what is a build system? I would love to</span>
<span>highlight a couple of slightly unconventional answers here.</span></p>
<p><em><span>First</span></em><span>, a build system is a bootstrap process: it is how you get from </span><code>git clone</code><span> to a working</span>
<span>binary. The two aspects of this boostrapping process are important:</span></p>
<ul>
<li>
<span>It should be simple. No</span>
<span class="display"><code>sudo apt-get install bazzilion packages</code><span>,</span></span>
<span>the single binary of your build system should be able to bring everything else that</span>&rsquo;<span>s needed,</span>
<span>automatically.</span>
</li>
<li>
<span>It should be repeatable. Your laptop and your CI should end up with exactly identical set of</span>
<span>dependencies. The end result should be a function of commit hash, and not your local shell</span>
<span>history, otherwise NRSR doesn</span>&rsquo;<span>t work.</span>
</li>
</ul>
<p><em><span>Second</span></em><span>, a build system is developer UI. To do almost anything, you need to type some sort of build</span>
<span>system invocation into your shell. There should be a single, clearly documented command for building</span>
<span>and testing the project. If it is not a single </span><code>makebelieve test</code><span>, something</span>&rsquo;<span>s wrong.</span></p>
<p><span>One anti-pattern here is when the build system spills over to CI. When, to figure out what the set</span>
<span>of checks even is, you need to read </span><code>.github/workflows/*.yml</code><span> to compile a list of commands. That</span>&rsquo;<span>s</span>
<span>accidental complexity! Sprawling yamls are a bad entry point. Put all the logic into the build</span>
<span>system and let the CI drive that, and not vice verse.</span></p>
<p><a href="https://matklad.github.io/2023/12/31/O(1)-build-file.html"><span>There is a stronger version of the</span>
<span>advice</span></a><span>. No matter the size of the</span>
<span>project, there</span>&rsquo;<span>s probably only a handful of workflows that make sense for it: testing, running,</span>
<span>releasing, etc. This small set of workflows should be nailed from the start, and specific commands</span>
<span>should be documented. When the project subsequently grows in volumes, this set of build-system entry</span>
<span>points should </span><em><span>not</span></em><span> grow.</span></p>
<p><span>If you add a Frobnicator, </span><code>makebelieve test</code><span> invocation </span><em><span>should</span></em><span> test that Frobnicator works. If</span>
<span>instead you need a dedicated </span><code>makebelieve test-frobnicator</code><span> and the corresponding line in some CI</span>
<span>yaml, you are on a perilous path.</span></p>
<p><em><span>Finally</span></em><span>, a build system is a collection of commands to make stuff happen. In larger projects,</span>
<span>you</span>&rsquo;<span>ll inevitably need some non-trivial amount of glue automation. Even if the entry point is just</span>
<code>makebelive release</code><span>, internally that might require any number of different tools to build, sign,</span>
<span>tag, upload, validate, and generate a changelog for a new release.</span></p>
<p><span>A common anti-pattern is to write these sorts of automations in bash and Python, but that</span>&rsquo;<span>s almost</span>
<span>pure technical debt. These ecosystems are extremely finnicky in and off themselves, and, crucially</span>
<span>(unless your project itself is written in bash or Python), they are a second ecosystem to what you</span>
<span>already have in your project for </span>&ldquo;<span>normal</span>&rdquo;<span> code.</span></p>
<p><span>But releasing software is also just code, which you can write in your primarly language.</span>
<a href="https://twitter.com/id_aa_carmack/status/989951283900514304"><span>The right tool for the job is often the tool you are already using</span></a><span>.</span>
<span>It pays off to explicitly attack the problem of glue from the start, and to pick/write a library</span>
<span>that makes writing subprocess wrangling logic easy.</span></p>
<p><span>Summing the build and CI story up:</span></p>
<p><span>Build system is self-contained, reproducible and takes on the task of downloading all external</span>
<span>dependencies. Irrespective of size of the project, it contains O(1) different entry points. One of</span>
<span>those entry points is triggered by the not rocket science rule CI infra to run the set of canonical</span>
<span>checks. There</span>&rsquo;<span>s an explicit support for free-form automation, which is implemented in the same</span>
<span>language as the bulk of the project.</span></p>
<p><span>Integration with NRSR is the most important aspect of the build process, as it determines how the</span>
<span>project evolves over time. Let</span>&rsquo;<span>s zoom in.</span></p>
</section>
<section id="Testing">

    <h2>
    <a href="#Testing"><span>Testing</span> </a>
    </h2>
<p><span>Testing is a primary architectural concern. When the first line of code is written, you already</span>
<span>should understand the big picture testing story. It is empathically </span><em><span>not</span></em><span> </span>&ldquo;<span>every class and module</span>
<span>has unit-test</span>&rdquo;<span>. Testing should be data oriented </span>&mdash;<span> the job of a particular software is to take some</span>
<span>data in, transform it, and spit different data out. Overall testing strategy requires:</span></p>
<ul>
<li>
<span>some way to specify/generate input data,</span>
</li>
<li>
<span>some way to assert desired properties of output data, and</span>
</li>
<li>
<span>a way to run many individual checks very fast.</span>
</li>
</ul>
<p><span>If time is a meaningful part of the input data, it should be modeled explicitly. Not getting the</span>
<span>testing architecture right usually results in:</span></p>
<ul>
<li>
<span>Software that is hard to change because thousands of test nail existing internal APIs.</span>
</li>
<li>
<span>Software that is hard to change because there are no test to confidently verify absence of</span>
<span>unintended breakages.</span>
</li>
<li>
<span>Software that is hard to change because each change requires hours of testing time to verify.</span>
</li>
</ul>
<p><span>How to architect a test suite goes beyond the scope of this article, but please read</span>
<a href="https://matklad.github.io/2022/07/04/unit-and-integration-tests.html"><span>Unit and Integration Tests</span></a>
<span>and</span>
<a href="https://matklad.github.io/2021/05/31/how-to-test.html"><span>How To Test</span></a><span>.</span></p>
<p><span>Some specific things that are in scope for this article:</span></p>
<p><span>Zero tolerance for flaky tests. Strict not rocket science rules gives this by construction </span>&mdash;<span> if</span>
<span>you can</span>&rsquo;<span>t merge </span><em><span>your</span></em><span> pull request because someone elses test is flaky, that flaky test immediately</span>
<span>becomes your problem.</span></p>
<p><span>Fast tests. Again, NRSR already provides a natural pressure for this, but it also helps to make</span>
<span>testing time more salient otherwise. Just by default printing the total test time and five slowest</span>
<span>tests in a run goes a long way.</span></p>
<p><span>Not all tests could be fast. Continuing the ying-yang theme of embracing order and chaos</span>
<span>simultaneously, it helps to introduce the concept of slow tests early on. CI always runs the full</span>
<span>suite of tests, fast and slow. But the local </span><code>makebelive test</code><span> by default runs only fast test, with</span>
<span>an opt-in for slow tests. Opt in can be as simple as an </span><code>SLOW_TESTS=1</code><span> environmental variable.</span></p>
<p><span>Introduce a </span><a href="https://ianthehenry.com/posts/my-kind-of-repl/"><span>snapshot testing</span></a><span> library early.</span>
<span>Although the bulk of tests should probably use project-specific testing harness, for everything else</span>
<span>inline repl-driven snapshot testing is a good default approach, and is something costly to introduce</span>
<span>once you</span>&rsquo;<span>ve accumulated a body of non-snapshot-based tests.</span></p>
<p><span>Alongside the tests, come the benchmarks.</span></p>
</section>
<section id="Benchmarking">

    <h2>
    <a href="#Benchmarking"><span>Benchmarking</span> </a>
    </h2>
<p><span>I don</span>&rsquo;<span>t have a grand vison about how to make benchmark work in a large, living project, it always</span>
<span>feels like a struggle to me. I do have a couple of tactical tips though.</span></p>
<p><em><span>Firstly</span></em><span>, any code that is </span><em><span>not</span></em><span> running during NRSR is effectively dead. It is exceedingly common</span>
<span>for benchmarks to be added alongside a performance improvement, and then </span><em><span>not</span></em><span> getting hooked up</span>
<span>with CI. So, two month down the line, the benchmark either stops compiling outright, or maybe just</span>
<span>panics at a startup due to some unrelated change.</span></p>
<p><span>This fix here is to make sure that every benchmark is </span><em><span>also</span></em><span> a test. Parametrize every benchmark by</span>
<span>input size, such that with a small input it finishes in milliseconds. Then write a test that</span>
<span>literally just calls the benchmarking code with this small input. And remember that your build</span>
<span>system should have O(1) entry points. Plug this into a </span><span class="display"><code>makebelieve test</code><span>,</span></span><span> not into a</span>
<span>dedicated </span><span class="display"><code>makebelieve benchmark --small-size</code><span>.</span></span></p>
<p><em><span>Secondly</span></em><span>, any large project has a certain amount of very important macro metrics.</span></p>
<ul>
<li>
<span>How long does it take to build?</span>
</li>
<li>
<span>How long does it take to test?</span>
</li>
<li>
<span>How large is the resulting artifact shipping to users?</span>
</li>
</ul>
<p><span>These are some of the questions that always matter. You need infrastructure to track these numbers,</span>
<span>and to see them regularly. This where the internal website and its data store come in. During CI,</span>
<span>note those number. After CI run, upload a record with commit hash, metric name, metric value</span>
<em><span>somewhere</span></em><span>. Don</span>&rsquo;<span>t worry if the results are noisy </span>&mdash;<span> you target the baseline here, ability to</span>
<span>notice large changes over time.</span></p>
<p><span>Two options for the </span>&ldquo;<span>upload</span>&rdquo;<span> part:</span></p>
<ul>
<li>
<p><span>Just put them into some </span><code>.json</code><span> file in a git repo, and LLM a bit of javascript to display a nice</span>
<span>graph from these data.</span></p>
</li>
<li>
<p><a href="https://nyrkio.com" class="url">https://nyrkio.com</a><span> is a surprisingly good SaaS offering that I can recommend.</span></p>
</li>
</ul>
</section>
<section id="Fuzz-Testing">

    <h2>
    <a href="#Fuzz-Testing"><span>Fuzz Testing</span> </a>
    </h2>
<p><span>Serious fuzz testing curiously shares characteristics of tests and benchmarks. Like a normal test, a</span>
<span>fuzz test informs you about a correctness issue in your application, and is reproducible. Like a</span>
<span>benchmark, it is (infinitely) long running and infeasible to do as a part of NRSR.</span></p>
<p><span>I don</span>&rsquo;<span>t yet have a good hang on how to most effectively integrate continuous fuzzing into</span>
<span>development process. I don</span>&rsquo;<span>t know what is the not rocket science rule of fuzzing. But two things</span>
<span>help:</span></p>
<p><em><span>First</span></em><span>, even if you can</span>&rsquo;<span>t run fuzzing loop during CI, you can run isolated seeds. To help ensure</span>
<span>that the fuzing code doesn</span>&rsquo;<span>t get broken, do the same thing as with benchmark </span>&mdash;<span> add a test that</span>
<span>runs fuzzing logic with a fixed seed and small, fast parameters. One variation here is that you can</span>
<span>use commit sha as random a seed </span>&mdash;<span> that way the code is still reproducible, but there is enough</span>
<span>variation to avoid dynamically dead code.</span></p>
<p><em><span>Second</span></em><span>, it is helpful to think about fuzzing in terms of level triggering. With tests, when you</span>
<span>make an erroneous commit, you immediately know that it breaks stuff. With fuzzing, you generally</span>
<span>discover this later, and a broken seed generally persists for several commits. So, as an output of</span>
<span>the fuzzer, I think what you want is </span><em><span>not</span></em><span> a set of GitHub issues, but rather a dashboard of sorts</span>
<span>which shows a table of recent commits and failing seeds for those commits.</span></p>
<p><span>With not rocket science rule firmly in place, it makes sense to think about releases.</span></p>
</section>
<section id="Releases">

    <h2>
    <a href="#Releases"><span>Releases</span> </a>
    </h2>
<p><span>Two core insights here:</span></p>
<p><em><span>First</span></em><span> release </span><em><span>process</span></em><span> is orthogonal from software being </span><em><span>production ready</span></em><span>. You can release</span>
<span>stuff before it is ready (provided that you add a short disclaimer to the readme). So, it pays off</span>
<span>to add proper release process early on, such that, when the time comes to actually release</span>
<span>software, it comes down to removing disclaimers and writing the announcement post, as all technical</span>
<span>work has been done ages ago.</span></p>
<p><em><span>Second</span></em><span>, software engineering in general observes reverse triangle inequality: to get from A to C,</span>
<span>it is faster to go from A to B and then from B to C, then moving from A to C atomically. If you make</span>
<span>a pull request, it helps to split it up into smaller parts. If you refactor something, it is faster</span>
<span>to first introduce a new working copy and then separately retire the old code, rather than changing</span>
<span>the thing in place.</span></p>
<p><span>Releases are no different: faster, more frequent releases are easier and less risky. Weekly cadence</span>
<span>works great, provided that you have a solid set of checks in your NRSR.</span></p>
<p><span>It is much easier to start with a state where almost nothing works, but there</span>&rsquo;<span>s a solid release</span>
<span>(with an empty set of features), and ramp up from there, than to hack with reckless abandon</span>
<em><span>without</span></em><span> thinking much about eventual release, and then scramble to decide which is ready and</span>
<span>releasable, a what should be cut.</span></p>
</section>
<section id="Summary">

    <h2>
    <a href="#Summary"><span>Summary</span> </a>
    </h2>
<p><span>I think that</span>&rsquo;<span>s it for today? That</span>&rsquo;<span>s a lot of small points! Here</span>&rsquo;<span>s a bullet list for convenient</span>
<span>reference:</span></p>
<ul>
<li>
<span>README as a landing page.</span>
</li>
<li>
<span>Dev docs.</span>
</li>
<li>
<span>User docs.</span>
</li>
<li>
<span>Structured dev docs (architecture and processes).</span>
</li>
<li>
<span>Unstructured ingest-optimized dev docs (code style, topical guides).</span>
</li>
<li>
<span>User website, beware of content gravity.</span>
</li>
<li>
<span>Ingest-optimized internal web site.</span>
</li>
<li>
<span>Meta documentation process </span>&mdash;<span> its everyone job to append to code style and process docs.</span>
</li>
<li>
<span>Clear code review protocol (in whose court is the ball currently?).</span>
</li>
<li>
<span>Automated check for no large blobs in a git repo.</span>
</li>
<li>
<span>Not rocket science rule.</span>
</li>
<li>
<span>Let</span>&rsquo;<span>s repeat: at </span><strong><span>all</span></strong><span> times, the main branch points at a commit hash which is known to pass a</span>
<span>set of well-defined checks.</span>
</li>
<li>
<span>No semi tests: if the code is not good enough to add to NRSR, it is deleted.</span>
</li>
<li>
<span>No flaky tests (mostly by construction from NRSR).</span>
</li>
<li>
<span>Single command build.</span>
</li>
<li>
<span>Reproducible build.</span>
</li>
<li>
<span>Fixed number of build system entry points. No separate lint step, a lint is a kind of a test.</span>
</li>
<li>
<span>CI delegates to the build system.</span>
</li>
<li>
<span>Space for ad-hoc automation in the main language.</span>
</li>
<li>
<span>Overarching testing infrastructure, grand unified theory of project</span>&rsquo;<span>s testing.</span>
</li>
<li>
<span>Fast/Slow test split (fast=seconds per test suite, slow=low digit minutes per test suite).</span>
</li>
<li>
<span>Snapshot testing.</span>
</li>
<li>
<span>Benchmarks are tests.</span>
</li>
<li>
<span>Macro metrics tracking (time to build, time to test).</span>
</li>
<li>
<span>Fuzz tests are tests.</span>
</li>
<li>
<span>Level-triggered display of continuous fuzzing results.</span>
</li>
<li>
<span>Inverse triangle inequality.</span>
</li>
<li>
<span>Weekly releases.</span>
</li>
</ul>
</section>
]]></content>
</entry>

<entry>
<title type="text">Zig defer Patterns</title>
<link href="https://matklad.github.io/2024/03/21/defer-patterns.html" rel="alternate" type="text/html" title="Zig defer Patterns" />
<published>2024-03-21T00:00:00+00:00</published>
<updated>2024-03-21T00:00:00+00:00</updated>
<id>https://matklad.github.io/2024/03/21/defer-patterns</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[A short note about some unexpected usages of Zig's defer statement.]]></summary>
<content type="html" xml:base="https://matklad.github.io/2024/03/21/defer-patterns.html"><![CDATA[
<h1><span>Zig defer Patterns</span> <time class="meta" datetime="2024-03-21">Mar 21, 2024</time></h1>
<p><span>A short note about some unexpected usages of Zig</span>&rsquo;<span>s </span><code>defer</code><span> statement.</span></p>
<p><span>This post assumes that you already know the basics about RAII, </span><code>defer</code><span> and </span><code>errdefer</code><span>. While</span>
<span>discussing the differences between them is not the point, I will allow myself one high level</span>
<span>comment. I don</span>&rsquo;<span>t like </span><code>defer</code><span> as a replacement for RAII: after writing Zig for some time, I am</span>
<span>relatively confident that humans are just not good at not forgetting defers, especially when</span>
&ldquo;<span>optional</span>&rdquo;<span> ownership transfer is at play (i.e, this function takes ownership of an argument, unless</span>
<span>an error is returned). But defer is good at discouraging RAII oriented programming. RAII encourages</span>
<span>binding lifetime of resources (such as memory) with lifetimes of individual domain objects (such as</span>
<span>a </span><code>String</code><span>). But often, in pursuit of performance and small code size, you want to separate the two</span>
<span>concerns, and let many domain objects to share the single pool of resources. Instead of each</span>
<span>individual string managing its own allocation, you might want to store the contents of all related</span>
<span>strings into a single continuously allocated buffer. Because RAII with defer is painful, Zig</span>
<span>naturally pushes you towards batching your resource acquisition and release calls, such that you have</span>
<span>far fewer resources than objects in your program.</span></p>
<p><span>But, as I</span>&rsquo;<span>ve said, this post isn</span>&rsquo;<span>t about all that. This post is about non-resource-oriented usages</span>
<span>of </span><code>defer</code><span>. There</span>&rsquo;<span>s more to defer than just RAII, it</span>&rsquo;<span>s a nice little powerful construct! This is way</span>
<span>to much ado already, so here come the patterns:</span></p>
<section id="Asserting-Post-Conditions">

    <h2>
    <a href="#Asserting-Post-Conditions"><span>Asserting Post Conditions</span> </a>
    </h2>
<p><code>defer</code><span> gives you poor man</span>&rsquo;<span>s contract programming in the form of</span></p>

<figure class="code-block">


<pre><code><span class="line">assert(precondition)</span>
<span class="line"><span class="hl-keyword">defer</span> assert(postcondition)</span></code></pre>

</figure>
<p><span>Real life </span><a href="https://github.com/tigerbeetle/tigerbeetle/blob/73bbc1a32ba2513e369764680350c099fe302285/src/vsr/grid.zig#L298-L309"><span>example</span></a><span>:</span></p>

<figure class="code-block">


<pre><code><span class="line">{</span>
<span class="line">  assert(<span class="hl-operator">!</span>grid.free_set.opened);</span>
<span class="line">  <span class="hl-keyword">defer</span> assert(grid.free_set.opened);</span>
<span class="line"></span>
<span class="line">  <span class="hl-comment">// Code to open the free set</span></span>
<span class="line">}</span></code></pre>

</figure>
</section>
<section id="Statically-Enforcing-Absence-of-Errors">

    <h2>
    <a href="#Statically-Enforcing-Absence-of-Errors"><span>Statically Enforcing Absence of Errors</span> </a>
    </h2>
<p><span>This is basically peak Zig:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">errdefer</span> <span class="hl-keyword">comptime</span> <span class="hl-keyword">unreachable</span></span></code></pre>

</figure>
<p><code>errdefer</code><span> runs when a function returns an error (e.g., when a </span><code>try</code><span> fails). </span><code>unreachable</code>
<span>crashes the program (in </span><code>ReleaseSafe</code><span>). But </span><code>comptime unreachable</code><span> straight up fails compilation</span>
<span>if the compiler tries to generate the corresponding runtime code. The three together ensure the</span>
<span>absence of error-returning paths.</span></p>
<p><span>Here</span>&rsquo;<span>s </span><a href="https://github.com/ziglang/zig/blob/1d82d7987acf7f020bcc6a976f9887a3556ef79c/lib/std/hash_map.zig#L1561-L1584"><span>an example</span></a>
<span>from the standard library, the function to grow a hash map:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-comment">// The function as a whole can fail...</span></span>
<span class="line"><span class="hl-keyword">fn</span><span class="hl-function"> grow</span>(</span>
<span class="line">  self: <span class="hl-operator">*</span>Self,</span>
<span class="line">  allocator: Allocator,</span>
<span class="line">  new_capacity: Size,</span>
<span class="line">) Allocator.Error<span class="hl-operator">!</span><span class="hl-type">void</span> {</span>
<span class="line">  <span class="hl-built_in">@setCold</span>(<span class="hl-literal">true</span>);</span>
<span class="line">  <span class="hl-keyword">var</span> map: Self = .{};</span>
<span class="line">  <span class="hl-keyword">try</span> map.allocate(allocator, new_capacity);</span>
<span class="line"></span>
<span class="line">  <span class="hl-comment">// ...but from this point on, failure is impossible</span></span>
<span class="line">  <span class="hl-keyword">errdefer</span> <span class="hl-keyword">comptime</span> <span class="hl-keyword">unreachable</span>;</span>
<span class="line"></span>
<span class="line">  <span class="hl-comment">// Code to rehash&amp;copy self to map</span></span>
<span class="line">  std.mem.swap(Self, self, <span class="hl-operator">&amp;</span>map);</span>
<span class="line">  map.deinit(allocator);</span>
<span class="line">}</span></code></pre>

</figure>
</section>
<section id="Logging-Errors">

    <h2>
    <a href="#Logging-Errors"><span>Logging Errors</span> </a>
    </h2>
<p><span>Zig</span>&rsquo;<span>s error handling mechanism provides only error code (a number) and an error trace. This is</span>
<span>usually plenty to programmatically handle the error in an application and for the operator to</span>
<span>debug a failure, but this is decidedly not enough to provide a nice report for the end user.</span>
<span>However, if you are in a business of reporting errors to users, you are likely writing an</span>
<span>application, and application might get away without propagating extra information about the error</span>
<span>to the caller. Often, there</span>&rsquo;<span>s enough context at the point where the error originates in the first</span>
<span>place to produce a user-facing report right there.</span></p>
<p><a href="https://github.com/tigerbeetle/tigerbeetle/blob/73bbc1a32ba2513e369764680350c099fe302285/src/tigerbeetle/benchmark_driver.zig#L158-L163"><span>Example:</span></a></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">const</span> port = port: {</span>
<span class="line">  <span class="hl-keyword">errdefer</span> <span class="hl-operator">|</span>err<span class="hl-operator">|</span> log.err(<span class="hl-string">&quot;failed to read the port number: {}&quot;</span>, .{err});</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">var</span> buf: [fmt.count(<span class="hl-string">&quot;{}<span class="hl-string">\n</span>&quot;</span>, .{maxInt(<span class="hl-type">u16</span>)})]<span class="hl-type">u8</span> = <span class="hl-literal">undefined</span>;</span>
<span class="line">  <span class="hl-keyword">const</span> len = <span class="hl-keyword">try</span> process.stdout.?.readAll(<span class="hl-operator">&amp;</span>buf);</span>
<span class="line">  <span class="hl-keyword">break</span> :port <span class="hl-keyword">try</span> fmt.parseInt(<span class="hl-type">u16</span>, buf[<span class="hl-numbers">0</span> .. len <span class="hl-operator">-</span><span class="hl-operator">|</span> <span class="hl-numbers">1</span>], <span class="hl-numbers">10</span>);</span>
<span class="line">};</span></code></pre>

</figure>
</section>
<section id="Post-Increment">

    <h2>
    <a href="#Post-Increment"><span>Post Increment</span> </a>
    </h2>
<p><span>Finally, </span><code>defer</code><span> can be used as an </span><code>i++</code><span> of sorts. </span><a href="https://github.com/tigerbeetle/tigerbeetle/blob/0.15.3/src/lsm/scan_buffer.zig#L97-L102"><span>For</span>
<span>example</span></a><span>,</span>
<span>here</span>&rsquo;<span>s how you can pop an item off a free list:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-keyword">pub</span> <span class="hl-keyword">fn</span><span class="hl-function"> acquire</span>(self: <span class="hl-operator">*</span>ScanBufferPool) Error<span class="hl-operator">!</span><span class="hl-operator">*</span><span class="hl-keyword">const</span> ScanBuffer {</span>
<span class="line">  <span class="hl-keyword">if</span> (self.scan_buffer_used <span class="hl-operator">==</span> constants.lsm_scans_max) {</span>
<span class="line">    <span class="hl-keyword">return</span> Error.ScansMaxExceeded;</span>
<span class="line">  }</span>
<span class="line"></span>
<span class="line">  <span class="hl-keyword">defer</span> self.scan_buffer_used <span class="hl-operator">+=</span> <span class="hl-numbers">1</span>;</span>
<span class="line">  <span class="hl-keyword">return</span> <span class="hl-operator">&amp;</span>self.scan_buffers[self.scan_buffer_used];</span>
<span class="line">}</span></code></pre>

</figure>
</section>
]]></content>
</entry>

<entry>
<title type="text">Kafka versus Nabokov</title>
<link href="https://matklad.github.io/2024/03/02/Kafka-vs-Nabokov.html" rel="alternate" type="text/html" title="Kafka versus Nabokov" />
<published>2024-03-02T00:00:00+00:00</published>
<updated>2024-03-02T00:00:00+00:00</updated>
<id>https://matklad.github.io/2024/03/02/Kafka-vs-Nabokov</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[Uplifting a lobste.rs comment to a stand-alone post.]]></summary>
<content type="html" xml:base="https://matklad.github.io/2024/03/02/Kafka-vs-Nabokov.html"><![CDATA[
<h1><span>Kafka versus Nabokov</span> <time class="meta" datetime="2024-03-02">Mar 2, 2024</time></h1>
<p><span>Uplifting a lobste.rs comment to a stand-alone post.</span></p>
<p><code>objectif_lune</code><span> </span><a href="https://lobste.rs/s/9xtcun/complex_systems_bridging_between_spec"><span>asks</span></a><span>:</span></p>

<figure class="blockquote">
<blockquote><p><span>I am on the cusp (hopefully) of kicking off development of a fairly large and complex system</span>
<span>(multiple integrated services, kafkas involved, background processes, multiple client frontends,</span>
<span>etc…). It’s predominantly going to be built in rust (but that’s only trivially relevant; i.e. not</span>
<span>following standard OOP).</span></p>
<p><span>Here’s where i’m at:</span></p>
<ol>
<li>
<span>I have defined all the components, services, data stores to use / or develop</span>
</li>
<li>
<span>I have a a fairly concrete conceptualisation of how to structure and manage data on the storage</span>
<span>end of the system which i’m formalizing into a specification</span>
</li>
<li>
<span>I have a deployment model for the various parts of the system to go into production</span>
</li>
</ol>
<p><span>The problem is, I have a gap, from these specs of the individual components and services that need</span>
<span>to be built out, to the actual implementation of those services. I’ve scaffolded the code-base</span>
<span>around what “feels” like sensible semantics, but bridging from the scope, through the high-level</span>
<span>code organisation through to implementation is where I start to get a bit queasy.</span></p>
<p><span>In the past, i’ve more or less dove head-first into just starting to implement, but the problem has</span>
<span>been that I will very easily end up going in circles, or I end up with a lot of duplicated code</span>
<span>across areas and just generally feel like it’s not working out the way I had hoped (obviously</span>
<span>because i’ve just gone ahead and implemented).</span></p>
<p><span>What are some tools, processes, design concepts, thinking patterns that you can use to sort of fill</span>
<span>in that “last mile” from high-level spec to implementing to try and ensure that things stay on track</span>
<span>and limit abandonment or going down dead-ends?</span></p>
<p><span>I’m interested in advice, articles, books, or anything else that makes sense in the rough context</span>
<span>above. Not specifically around for instance design patterns themselves, i’m more than familiar with</span>
<span>the tools in that arsenal, but how do you bridge the gap between the concept and the implementation</span>
<span>without going too deep down the rabbit-hole of modelling out actual code and everything else in UML</span>
<span>for instance? How do you basically minimize getting mired in massive refactors once you get to</span>
<span>implementation phase?</span></p>
</blockquote>

</figure>
<p><span>My answer:</span></p>
<hr>
<p><span>I don’t have much experience building these kind of systems (I like Kafka, but I must say I prefer</span>
<span>Nabokov’s rendition of similar ideas in “Invitation to a Beheading” and “Pale Fire” more), but</span>
<span>here’s a couple of things that come to mind.</span></p>
<p><span>First, </span><a href="https://en.wikipedia.org/wiki/John_Gall_(author)#Gall's_law"><span>every complex system that works started out as a simple system that worked</span></a><span>. Write code top</span>
<span>down: </span><a href="https://www.teamten.com/lawrence/programming/write-code-top-down.html" class="display url">https://www.teamten.com/lawrence/programming/write-code-top-down.html</a></p>
<p><span>Even if it is a gigantic complex system with many moving parts, start with spiking and end-to-end</span>
<span>solution which can handle one particular variation of a happy path. Build skeleton first, flesh can</span>
<span>be added incrementally.</span></p>
<p><span>To do this, you’ll need some way to actually run the entire system while it isn’t deployed yet,</span>
<span>which is something you need to solve before you start writing pages of code.</span></p>
<p><span>Similarly, include testing strategy in the specification, and start with one single simple</span>
<span>end-to-end test. I think that TDD as a way to design a class or a function is mostly snake oil</span>
<span>(because </span><a href="https://matklad.github.io/2021/05/31/how-to-test.html"><span>“unit” tests are mostly snake</span>
<span>oil</span></a><span>), but the overall large scale design of</span>
<span>the system should absolutely be driven by the way the system will be tested.</span></p>
<p><span>It is helpful to dwell on these two laws:</span></p>
<p><a href="https://martinfowler.com/articles/distributed-objects-microservices.html"><strong><strong><span>First Law of Distributed Object Design:</span></strong></strong></a></p>

<figure class="blockquote">
<blockquote><p><span>Don’t distribute your objects.</span></p>
</blockquote>

</figure>
<p><a href="https://en.wikipedia.org/wiki/Conway%27s_law"><strong><strong><span>Conway’s law:</span></strong></strong></a></p>

<figure class="blockquote">
<blockquote><p><span>Organizations which design systems are constrained to produce designs which are copies of the</span>
<span>communication structures of these organizations.</span></p>
</blockquote>

</figure>
<p><span>The code architecture of your solution is going to be isomorphic to your org chart, not to your</span>
<span>deployment topology. Let’s say you want to deploy three different services: </span><code>foo</code><span>, </span><code>bar</code><span>, and </span><code>baz</code><span>.</span>
<span>Just put all three into a single binary, which can be invoked as </span><code>app foo</code><span>, </span><code>app bar</code><span>, and </span><code>app
baz</code><span>. This mostly solves any code duplication issues — if there’s shared code, just call it!</span></p>
<p><span>Finally, system boundaries are the focus of the design:</span>
<a href="https://www.tedinski.com/2018/02/06/system-boundaries.html" class="display url">https://www.tedinski.com/2018/02/06/system-boundaries.html</a></p>
<p><span>Figure out hard system boundaries between “your system” and “not your system”, and do design those</span>
<span>carefully. Anything else that looks like a boundary isn’t. It is useful to spend some effort</span>
<span>designing those things as well, but it’s more important to make sure that you can easily change</span>
<span>them. Solid upgrade strategy for deployment trumps any design which seems perfect at a given moment</span>
<span>in time.</span></p>
]]></content>
</entry>

<entry>
<title type="text">Window: Live, Constant Time Grep</title>
<link href="https://matklad.github.io/2024/02/10/window-live-constant-time-grep.html" rel="alternate" type="text/html" title="Window: Live, Constant Time Grep" />
<published>2024-02-10T00:00:00+00:00</published>
<updated>2024-02-10T00:00:00+00:00</updated>
<id>https://matklad.github.io/2024/02/10/window-live-constant-time-grep</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[In this post, I describe the design of window --- a small
grep-like utility I implemented in 500 lines of Rust. The utility itself is likely not that
interesting --- I bet some greybeared can implement an equivalent in 5 lines of bash. But the
design principles behind it might be interesting --- this small utility manages to combine core
ideas of rust-analyzer and TigerBeetle!]]></summary>
<content type="html" xml:base="https://matklad.github.io/2024/02/10/window-live-constant-time-grep.html"><![CDATA[
<h1><span>Window: Live, Constant Time Grep</span> <time class="meta" datetime="2024-02-10">Feb 10, 2024</time></h1>
<p><span>In this post, I describe the design of </span><a href="https://github.com/matklad/window/"><span>window</span></a><span> </span>&mdash;<span> a small</span>
<span>grep-like utility I implemented in 500 lines of Rust. The utility itself is likely not that</span>
<span>interesting </span>&mdash;<span> I bet some greybeared can implement an equivalent in 5 lines of bash. But the</span>
<span>design principles behind it might be interesting </span>&mdash;<span> this small utility manages to combine core</span>
<span>ideas of rust-analyzer and TigerBeetle!</span></p>
<section id="Problem-Statement">

    <h2>
    <a href="#Problem-Statement"><span>Problem Statement</span> </a>
    </h2>
<p><span>TigerBeetle is tested primarily through a deterministic simulator: a cluster of replicas runs in a</span>
<span>single process (in a single thread even), replicas are connected to a virtual network and a virtual</span>
<span>hard drive. Both the net and the disk are extra nasty, and regularly drop, reorder, and corrupt IO</span>
<span>requests. The cluster has to correctly process randomly generated load in spite of this radioactive</span>
<span>environment. You can play with visualization of the simulator here:</span>
<a href="https://sim.tigerbeetle.com" class="display url">https://sim.tigerbeetle.com</a></p>
<p><span>Of course, sometimes we have bugs, and need to debug crashes found by the simulator. Because</span>
<span>everything is perfectly deterministic, a crash is a pair of commit hash and a seed for a random</span>
<span>number generator. We don</span>&rsquo;<span>t yet have any minimization infrastructure, so some crashes tend to be</span>
<span>rather large: a debug log from a crash can easily reach 50 gigabytes!</span></p>
<p><span>So that</span>&rsquo;<span>s my problem: given multi-gigabyte log of a crash, find a dozen or so of log-lines which</span>
<span>explain the crash.</span></p>
<p><span>I think you are supposed to use </span><code>coreutils</code><span> to solve this problem, but I am not good enough with</span>
<span>grep to make that efficient: my experience that grepping anything in this large file takes seconds,</span>
<span>and still produces gigabytes of output which is hard to make heads or tails of.</span></p>
<p><span>I had relatively more success with </span><a href="https://lnav.org"><span>lnav.org</span></a><span>, but:</span></p>
<ul>
<li>
<span>it is still slower than I would like,</span>
</li>
<li>
<span>it comes with its own unique TUI interface, shortcuts, and workflow, which is at odds with my</span>
<span>standard editing environment.</span>
</li>
</ul>
</section>
<section id="Window">

    <h2>
    <a href="#Window"><span>Window</span> </a>
    </h2>
<p><span>So, I made </span><code>window</code><span>. You run it as</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-title function_">$</span> window huge-file.log &amp;</span></code></pre>

</figure>
<p><span>It then creates two files:</span></p>
<ul>
<li>
<code>window.toml</code><span> </span>&mdash;<span> the file with the input query,</span>
</li>
<li>
<code>huge-file.log.window</code><span> </span>&mdash;<span> the result of the query.</span>
</li>
</ul>
<p><span>You open both files side-by-side in your editor of choice. Edits to the query file are immediately</span>
<span>reflected in the results file (assuming the editor has auto-save and automatically reloads files</span>
<span>changed on disk):</span></p>
<p><span>Here</span>&rsquo;<span>s a demo in Emacs (you might want to full-screen that video):</span></p>
<script async id="asciicast-637434" src="https://asciinema.org/a/637434.js"></script>
<p><span>In the demo, I have to manually save the </span><code>window.toml</code><span> file with </span><code>C-x C-s</code><span>, but in my</span>
<span>actual usage in VS Code the file is saved automatically after 100ms.</span></p>
<p><span>As you can see, </span><code>window</code><span> is pretty much instant. How is this possible?</span></p>
</section>
<section id="When-Best-Ideas-of-rust-analyzer-and-TigerBeetle-are-Combined-in-a-Tool-of-Questionable-Usefulness">

    <h2>
    <a href="#When-Best-Ideas-of-rust-analyzer-and-TigerBeetle-are-Combined-in-a-Tool-of-Questionable-Usefulness"><span>When Best Ideas of rust-analyzer and TigerBeetle are Combined in a Tool of Questionable</span>
<span>Usefulness</span> </a>
    </h2>
<p><span>Let</span>&rsquo;<span>s take a closer look at that query string:</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-attr">reverse</span> = <span class="hl-literal">false</span></span>
<span class="line"><span class="hl-attr">position</span> = <span class="hl-string">&quot;0%&quot;</span></span>
<span class="line"><span class="hl-attr">anchor</span> = <span class="hl-string">&quot;&quot;</span></span>
<span class="line"><span class="hl-attr">source_bytes_max</span> = <span class="hl-number">104857600</span></span>
<span class="line"><span class="hl-attr">target_bytes_max</span> = <span class="hl-number">102400</span></span>
<span class="line"><span class="hl-attr">target_lines_max</span> = <span class="hl-number">50</span></span>
<span class="line"><span class="hl-attr">filter_in</span> = [</span>
<span class="line">      [<span class="hl-string">&quot;(replica): 0&quot;</span>, <span class="hl-string">&quot;view=74&quot;</span>],</span>
<span class="line">      [<span class="hl-string">&quot;(replica): 1&quot;</span>, <span class="hl-string">&quot;view=74&quot;</span>]</span>
<span class="line">]</span>
<span class="line"><span class="hl-attr">filter_out</span> = [</span>
<span class="line">       <span class="hl-string">&quot;ping&quot;</span>, <span class="hl-string">&quot;pong&quot;</span></span>
<span class="line">]</span></code></pre>

</figure>
<p><span>The secret sauce are </span><code>source_bytes_max</code><span> and </span><code>target_bytes_max</code><span> parameters.</span></p>
<p><span>Let</span>&rsquo;<span>s start with </span><code>target_bytes_max</code><span>. This is a lesson from </span><code>rust-analyzer</code><span>. For dev tools, the user</span>
<span>of software is a human. Humans are slow, and can</span>&rsquo;<span>t process a lot of information. That means it is</span>
<span>generally useless to produce more than a hundred lines of output </span>&mdash;<span> a human won</span>&rsquo;<span>t be able to make</span>
<span>use of a larger result set </span>&mdash;<span> they</span>&rsquo;<span>d rather refine the query than manually sift through pages of</span>
<span>results.</span></p>
<p><span>So, when designing software to execute a user-supplied query, the inner loop should have some idea</span>
<span>about the amount of results produced so far, and a short-circuiting logic. It is more valuable to</span>
<span>produce some result quickly and to inform the user that the query is not specific, than to spend a</span>
<span>second computing the full result set.</span></p>
<p><span>A similar assumption underpins the architecture of a lot of language servers. No matter the size of</span>
<span>the codebase, the amount of information displayed on the screen in user</span>&rsquo;<span>s IDE at a given point in</span>
<span>time is O(1). A typical successful language server tries hard to do the absolute minimal amount of</span>
<span>work to compute the relevant information, and nothing more.</span></p>
<p><span>So, the </span><code>window</code><span>, by default, limits the output size to the minimum of 100 kilobytes / 50 lines, and</span>
<span>never tries to compute more than that. If the first 50 lines of the output don</span>&rsquo;<span>t contain the result,</span>
<span>the user can make the query more specific by adding more AND terms to </span><code>filter_in</code><span> causes, or adding</span>
<span>OR terms to </span><code>filter_out</code><span>.</span></p>
<p><span>TigerBeetle gives </span><code>window</code><span> the second magic parameter </span>&mdash;<span> </span><code>source_bytes_max</code><span>. The big insight of</span>
<span>TigerBeetle is that all software always has limits. Sometimes the limit is a  hard wall: if a server</span>
<span>runs out of file descriptors, it just crashes. The limit can also be a soft, sloughy bog as well: if</span>
<span>the server runs out of memory, it might start paging memory in and out, slowing to a crawl. Even if</span>
<span>some requests are, functionally speaking, fulfilled, the results are useless, as they arrive too</span>
<span>late. Or, in other words, every request has a (potentially quite large) latency window.</span></p>
<p><span>It might be a good idea to make the limits explicit, and design software around them. That gives</span>
<span>predictable performance, and allows the user to manually chunk larger requests in manageable pieces.</span></p>
<p><span>That is exactly what </span><code>window</code><span> does. Grepping 100 megabytes is pretty fast. Grepping more might be</span>
<span>slow. So </span><code>window</code><span> just doesn</span>&rsquo;<span>t do it. Here</span>&rsquo;<span>s a rough rundown of the algorithm:</span></p>
<ol>
<li>
<code>mmap</code><span> the entire input file to a </span><code>&amp;[u8]</code><span>.</span>
</li>
<li>
<span>Wait until the control file (</span><code>window.toml</code><span>) changes and contains a valid query.</span>
</li>
<li>
<span>Convert the </span><code>position</code><span> field (which might be absolute or a percentage) to an absolute offset.</span>
</li>
<li>
<span>Select slice of </span><code>source_bytes_max</code><span> starting at that offset.</span>
</li>
<li>
<span>Adjust boundaries of the slice to be on </span><code>\n</code><span>.</span>
</li>
<li>
<span>Iterate lines.</span>
</li>
<li>
<span>If a line matches any of </span><code>filter_out</code><span> conditions, skip over it.</span>
</li>
<li>
<span>If a line matches any of </span><code>filter_in</code><span> conditions, add it to the result.</span>
</li>
<li>
<span>Break when reaching the end of </span><code>source_bytes_max</code><span> window, or when the size of output exceeds</span>
<code>target_bytes_max</code><span>.</span>
</li>
</ol>
<p><span>The deal is:</span></p>
<ul>
<li>
<span>It</span>&rsquo;<span>s on the user to position a limited window over the interesting part of the input.</span>
</li>
<li>
<span>In exchange, the </span><code>window</code><span> tool guarantees constant-time performance.</span>
</li>
</ul>
</section>
<section id="Limits-of-Applicability">

    <h2>
    <a href="#Limits-of-Applicability"><span>Limits of Applicability</span> </a>
    </h2>
<p><span>Important pre-requisites to make the </span>&ldquo;<span>limit the size of the output</span>&rdquo;<span> work are:</span></p>
<ul>
<li>
<span>The user can refine the query.</span>
</li>
<li>
<span>The results are computed instantly.</span>
</li>
</ul>
<p><span>If these assumptions are violated, it might be best to return the full list of results.</span></p>
<p><span>Here</span>&rsquo;<span>s one counterexample! I love reading blogs. When I find a great post, I often try to read all</span>
<span>other posts by the same author </span>&mdash;<span> older posts which are still relevant usually are much more</span>
<span>valuable then the news of the day. I love when blogs have a simple chronological list of all</span>
<span>articles, a-la: </span><a href="https://matklad.github.io" class="display url">https://matklad.github.io</a></p>
<p><span>Two blogging platforms mess up this feature:</span></p>
<p><span>WordPress blogs love to have </span>&ldquo;<span>archives</span>&rdquo;<span> organized by month, where a month</span>&rsquo;<span>s page typically has 1 to</span>
<span>3 entries. What</span>&rsquo;<span>s more, WordPress loves to display a couple of pages of content for each entry. This</span>
<span>is just comically unusable </span>&mdash;<span> the amount of </span><em><span>entries</span></em><span> on a page is too few to effectively search</span>
<span>them, but the actual amount of content on a page is overwhelming.</span></p>
<p><span>Substack</span>&rsquo;<span>s archive is an infinite scroll that fetches 12 entries at a time. 12 entries is a joke!</span>
<span>It</span>&rsquo;<span>s only 1kb compressed, and is clearly bellow human processing limit. There </span><em><span>might</span></em><span> be some</span>
<span>argument for client-side pagination to postpone loading of posts</span>&rsquo;<span> images, but feeding the posts</span>
<span>themselves over the network one tiny droplet at a time seems excessive.</span></p>
<hr>
<p><span>To recap:</span></p>
<ul>
<li>
<p><span>Limiting </span><em><span>output</span></em><span> size might be a good idea, because, with a human on the other side of display,</span>
<span>any additional line of output has a diminishing return (and might even be a net-negative). On the</span>
<span>other hand, constant-time output allows reducing latency, and can even push a batch workflow into</span>
<span>an interactive one</span></p>
</li>
<li>
<p><span>Limiting </span><em><span>input</span></em><span> size might be a good idea, because the input is </span><em><span>always</span></em><span> limited anyway. The</span>
<span>question is whether you know the limit, and whether the clients know how to cut their queries into</span>
<span>reasonably-sized batches.</span></p>
</li>
<li>
<p><span>If you have exactly the same 20 GB log file problems as me, you might install </span><code>window</code><span> with</span></p>

<figure class="code-block">


<pre><code><span class="line"><span class="hl-title function_">$</span> cargo install --git https://github.com/matklad/window</span></code></pre>

</figure>
</li>
</ul>
</section>
]]></content>
</entry>

<entry>
<title type="text">Write Less</title>
<link href="https://matklad.github.io/2024/01/12/write-less.html" rel="alternate" type="text/html" title="Write Less" />
<published>2024-01-12T00:00:00+00:00</published>
<updated>2024-01-12T00:00:00+00:00</updated>
<id>https://matklad.github.io/2024/01/12/write-less</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[If we wish to count lines of code, we should not regard them as lines produced but as lines spent]]></summary>
<content type="html" xml:base="https://matklad.github.io/2024/01/12/write-less.html"><![CDATA[
<h1><span>Write Less</span> <time class="meta" datetime="2024-01-12">Jan 12, 2024</time></h1>

<figure class="blockquote">
<blockquote><p><span>If we wish to count lines of code, we should not regard them as </span>&ldquo;<span>lines produced</span>&rdquo;<span> but as </span>&ldquo;<span>lines spent</span>&rdquo;</p>
</blockquote>
<figcaption><cite><a href="https://www.cs.utexas.edu/users/EWD/transcriptions/EWD10xx/EWD1036.html"><span>Dijkstra</span></a></cite></figcaption>
</figure>
<p><span>The same applies to technical writing. There</span>&rsquo;<span>s a tendency to think that the more is written, the</span>
<span>better. It is wrong: given the same information content, a shorter piece of prose is easier to</span>
<span>understand, up to a reasonable limit.</span></p>
<p><span>To communicate effectively, write a bullet-point list of ideas that you need to get across. Then,</span>
<span>write a short paragraph in simple language that communicates these ideas precisely.</span></p>
]]></content>
</entry>

<entry>
<title type="text">Of Rats and Ratchets</title>
<link href="https://matklad.github.io/2024/01/03/of-rats-and-ratchets.html" rel="alternate" type="text/html" title="Of Rats and Ratchets" />
<published>2024-01-03T00:00:00+00:00</published>
<updated>2024-01-03T00:00:00+00:00</updated>
<id>https://matklad.github.io/2024/01/03/of-rats-and-ratchets</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[This is going to be related to software engineering, pinky promise!]]></summary>
<content type="html" xml:base="https://matklad.github.io/2024/01/03/of-rats-and-ratchets.html"><![CDATA[
<h1><span>Of Rats and Ratchets</span> <time class="meta" datetime="2024-01-03">Jan 3, 2024</time></h1>
<p><span>This is going to be related to software engineering, pinky promise!</span></p>
<p><span>I was re-reading Doctor Zhivago by Boris Pasternak recently. It is a beautiful novel set in Russia</span>
<span>during the revolutionary years before World War II. It focuses on the life of Yuri Zhivago, a doctor</span>
<span>and a poet, while the Russian revolutions roar in the background. It is a poignant and topical tale</span>
<span>of a country descending into blood-thirsty madness.</span></p>
<p><span>Being a doctor, a literati, and a descendant of once wealthy family, Zhivago is not exactly welcomed</span>
<span>in the new Russia. That</span>&rsquo;<span>s why a significant part of the novel takes place far away from Moscow and</span>
<span>St. Petersburg, in Siberia, where it is easier for undesirables to exist in a fragile truce with the</span>
<span>state.</span></p>
<p><span>What</span>&rsquo;<span>s your first problem, if you are going to live in someone else</span>&rsquo;<span>s abandoned house in Siberia,</span>
<span>eking out a living off whatever supplies had been left? The rats, who are also very keen on the said</span>
<span>supplies. Clearly, rats are a big problem, and require immediate attention.</span></p>
<p><span>It</span>&rsquo;<span>s easy to exert effort and get rid of the rats </span>&mdash;<span> take a broom, some light source, and just</span>
<span>chase away the rascals from the house. However observably effective the method is, it is not a</span>
<span>solution </span>&mdash;<span> the rats will come back as soon as you are asleep. The proper solution starts with</span>
<span>identifying all the holes through which the pest gets in, and thoroughly plugging those! Only then</span>
<span>can you hope that the house </span><em><span>stays</span></em><span> rat free.</span></p>
<p><span>I feel the dynamics plays out in software projects. There</span>&rsquo;<span>s lots of rats, everything</span>&rsquo;<span>s broken and in</span>
<span>need of fixing, all the time. And there</span>&rsquo;<span>s usually plenty of desire and energy to fix things. The</span>
<span>problem is, often times the fixes are not durable </span>&mdash;<span> an immediate problem is resolved promptly, but</span>
<span>then it returns back two years down the line. This is most apparent in benchmarks </span>&mdash;<span> everyone loves</span>
<span>adding a microbenchmark to motivate a particular change, and then the benchmark bitrots with no one</span>
<span>to run it.</span></p>
<p><span>It</span>&rsquo;<span>s important not only to fix things, but to fix them in a durable way; to seal up the holes, not</span>
<span>just to wave the broom vigorously.</span></p>
<p><span>The best way to do this is to setup a not rocket science rule, and then to use it as a ratchet to</span>
<span>monotonically increase the set of properties the codebase possesses, one small check at a time.</span>
<span>Crucially, the ratchet should be set up up front, </span><em><span>before</span></em><span> any of the problems are actually fixed,</span>
<span>and it must allow for incremental steps.</span></p>
<p><span>Let</span>&rsquo;<span>s say you lack documentation, and want to ensure that every file in the code-base has a</span>
<span>top-level comment explaining  the relevant context. A good way to approach this problem is to write</span>
<span>a test that reads every file in the project, computes the set of poorly documented files, and xors</span>
<span>that against the hard-coded naughty list. This test is then committed to the project with the</span>
<span>naughty list encompassing all the existing files. Although no new docs are added, the ratchet is in</span>
<span>place </span>&mdash;<span> all new files are guaranteed to be documented. And its easier to move a notch up the</span>
<span>ratchet by documenting a single file and crossing it out from the naughty list.</span></p>
<p><span>More generally, widen your view of tests </span>&mdash;<span> a test is a program that checks a property of a</span>
<span>repository of code at a particular commit. Any property </span>&mdash;<span> code style, absence of warnings,</span>
<span>licenses of dependencies, the maximum size of any binary file committed into the repository,</span>
<span>presence of unwanted merge commits, average assertion density.</span></p>
<p><span>Not everything can be automated though. For things which can</span>&rsquo;<span>t be, the best trick I</span>&rsquo;<span>ve found is</span>
<span>writing them down. </span><em><span>Just</span></em><span> agreeing that </span><em><span>X</span></em><span> is a team practice is not enough, even if it </span><em><span>might</span></em>
<span>work for the first six months. Only when </span><em><span>X</span></em><span> is written down in a markdown document inside a</span>
<span>repository it might becomes a durable practice. But beware </span>&mdash;<span> document what </span><em><span>is</span></em><span>, rather than what</span>
<em><span>should</span></em><span> be. If there</span>&rsquo;<span>s a clear disagreement between what the docs say the world is, and the actual</span>
<span>world, the ratcheting effect of the written word disappears. If there</span>&rsquo;<span>s a large diff between reality</span>
<span>and documentation, don</span>&rsquo;<span>t hesitate to remove conflicting parts of the documentation. Having a ratchet</span>
<span>that enforces a tiny set of properties is much more valuable than aspirations to enforce everything.</span></p>
<p><span>Coming back to Doctor Zhivago, it is worth noting that the novel is arranged into a myriad of</span>
<span>self-contained small chapters </span>&mdash;<span> a blessing for a modern attention-deprived world, as it creates a</span>
<span>clear sense of progression even when you don</span>&rsquo;<span>t have enough focus to get lost in a book for hours.</span></p>
]]></content>
</entry>

<entry>
<title type="text">Git Things</title>
<link href="https://matklad.github.io/2023/12/31/git-things.html" rel="alternate" type="text/html" title="Git Things" />
<published>2023-12-31T00:00:00+00:00</published>
<updated>2023-12-31T00:00:00+00:00</updated>
<id>https://matklad.github.io/2023/12/31/git-things</id>
<author><name>Alex Kladov</name></author>
<summary type="html"><![CDATA[A grab bag of less frequently talked about git adjacent points.]]></summary>
<content type="html" xml:base="https://matklad.github.io/2023/12/31/git-things.html"><![CDATA[
<h1><span>Git Things</span> <time class="meta" datetime="2023-12-31">Dec 31, 2023</time></h1>
<p><span>A grab bag of less frequently talked about git adjacent points.</span></p>
<section id="Not-Rocket-Science-Rule-Applies-To-Merge-Commits">

    <h2>
    <a href="#Not-Rocket-Science-Rule-Applies-To-Merge-Commits"><span>Not Rocket Science Rule Applies To Merge Commits</span> </a>
    </h2>
<p><span>Should every commit pass the tests? If it should, then your </span><a href="https://graydon2.dreamwidth.org/1597.html"><span>not rocket science</span>
<span>rule</span></a><span> implementation must be verifying this property. It</span>
<span>probably doesn</span>&rsquo;<span>t, and only tests the final result of merging the feature branch into the main</span>
<span>branch.</span></p>
<p><span>That</span>&rsquo;<span>s why for typical project it is useful to </span><em><span>merge</span></em><span> pull requests into the main branch </span>&mdash;<span> the</span>
<span>linear sequence of merge commits is a record of successful CI runs, and is a set of commits you want</span>
<span>to </span><code>git bisect</code><span> over.</span></p>
<p><span>Within a feature branch, not every commit necessary passes the tests (or even builds), and that is a</span>
<span>useful property! Here</span>&rsquo;<span>s some ways this can be exploited:</span></p>
<ul>
<li>
<p><span>When fixing a bug, add a failing test first, as a separate commit.</span>
<span>That way it becomes easy to verify for anyone that the test indeed fails without the follow up</span>
<span>fix.</span></p>
<p><span>Related advice: often I see people commenting out tests that currently fail, or tests that are yet</span>
<span>to be fixed in the future. That</span>&rsquo;<span>s bad, because commented-out code rots faster than the JavaScript</span>
<span>framework of the day. Instead, adjust the asserts such that they lock down the current (wrong)</span>
<span>behavior, and add a clear </span><code>// TODO:</code><span> comment explaining what would be the correct result. This</span>
<span>prevents such tests from rotting and also catches cases where the behavior is fixed by an</span>
<span>unrelated change.</span></p>
</li>
<li>
<p><span>To refactor an API which has a lot of usages, split the work in two commits. In the first commit,</span>
<span>change the API itself, but don</span>&rsquo;<span>t touch the usages. In the second commit, mechanically adjust all</span>
<span>call sites.</span></p>
<p><span>That way during review it is trivial to separate meaningful changes from a large, but trivial</span>
<span>diff.</span></p>
</li>
<li>
<p><code>git mv</code><span> is fake. For a long time, I believed that </span><code>git mv</code><span> adds some special bit of git metadata</span>
<span>which tells it that the file was moved, such that it can be understood by </span><code>diff</code><span> or </span><code>blame</code><span>.</span>
<span>That</span>&rsquo;<span>s not the case: </span><code>git mv</code><span> is essentially </span><code>mv</code><span> followed by </span><code>git add</code><span>. There</span>&rsquo;<span>s nothing in git to</span>
<span>track that a file was moved specifically, the </span>&ldquo;<span>moved</span>&rdquo;<span> illusion is created by the diff tool when it</span>
<span>heuristically compares repository state at two points in time.</span></p>
<p><span>For this reason, if you want to reliably record file moves during refactors in git, you should do</span>
<span>two commits: the first commit </span><em><span>just</span></em><span> moves the file without any changes, the second commit applies</span>
<span>all the required fixups.</span></p>
<p><span>Speaking of moves, consider adding this to your </span><code>gitconfig</code><span>:</span></p>

<figure class="code-block">


<pre><code><span class="line">[diff]</span>
<span class="line">  colormoved = "default"</span>
<span class="line">  colormovedws = "allow-indentation-change"</span></code></pre>

</figure>
<p><span>This way, moved lines will be colored differently in </span><code>diff</code><span>, so that code motions not confused</span>
<span>with additions and deletions, and are easier to review. It is unclear to me why this isn</span>&rsquo;<span>t the</span>
<span>default, and why this isn</span>&rsquo;<span>t an option in GitHub</span>&rsquo;<span>s UI.</span></p>
</li>
</ul>
<p>&ldquo;<span>Merge into main, but rebase feature branches</span>&rdquo;<span> might be a hard rule to wrap your head around if you</span>
<span>are new to git. Luckily, it</span>&rsquo;<span>s easy to use not-rocket-science rule to enforce this property. The</span>
<span>history is as much a part of your project as is the source code. You can write a test that shells</span>
<span>out to git and checks that the only merge commits in the history are those from the merge bot. While</span>
<span>you are at it, it would be a good idea to test that no large large files are present in the</span>
<span>repository </span>&mdash;<span> the size of a repository only grows, and you can</span>&rsquo;<span>t easily remove large blobs from the</span>
<span>repo later on!</span></p>
</section>
<section id="Commit-Messages">

    <h2>
    <a href="#Commit-Messages"><span>Commit Messages</span> </a>
    </h2>
<p><span>Let me phrase this in the most inflammatory way possible :)</span></p>
<p><span>If your project has great commit messages, with short and precise summary lines and long and</span>
<span>detailed bodies, this probably means that your CI and code review process suck.</span></p>
<p><span>Not all changes are equal. In a typical project, most of the changes that </span><em><span>should</span></em><span> be made are small</span>
<span>and trivial </span>&mdash;<span> some renames, visibility tightening, </span>&ldquo;<span>attention to details</span>&rdquo;<span> polish in user-visible</span>
<span>features.</span></p>
<p><span>However, in a typical project, landing a trivial change is slow. How long would it take you to fix</span>
<code>it's/its</code><span> typo in a comment? Probably 30 seconds to push the actual change, 30 minutes to get the</span>
<span>CI results, and 3 hours for a review roundtrip.</span></p>
<p><span>The fixed costs to making a change are tremendous. Main branch gatekeeping strongly incentivizes</span>
<span>against trivial changes. As a result, such changes either are not being made, or are tacked onto</span>
<span>larger changes as a drive by bonus. In any case, the total number of commits and PRs goes down. And</span>
<span>you are crafting a novel of a commit message because you have to wait for your previous PR to land</span>
<span>anyway.</span></p>
<p><span>What can be done better?</span></p>
<p><em><span>First</span></em><span>, make changes smaller and more frequent.</span>
<span>Most likely, this is possible for you.</span>
<span>At least, I tend to out-commit most colleagues (</span><a href="https://github.com/intellij-rust/intellij-rust/graphs/contributors"><span>example</span></a><span>).</span>
<span>That</span>&rsquo;<span>s not because I am more productive </span>&mdash;<span> I just do work in smaller batches.</span></p>
<p><em><span>Second</span></em><span>, make CI asynchronous.</span>
<span>At no point in your workflow you should be waiting for CI to pass.</span>
<span>You should flag a change for merging, move on to the next thing, and only get back if CI fails.</span>
<span>This is something bors-ng does right </span>&mdash;<span> it</span>&rsquo;<span>s possible to </span><code>r+</code><span> a commit immediately on submission.</span>
<span>This is something GitHub merge queue does wrong </span>&mdash;<span> it</span>&rsquo;<span>s impossible to add a PR to queue until checks on the PR itself are green.</span></p>
<p><em><span>Third</span></em><span>, our review process is backwards. Review is done </span><em><span>before</span></em><span> code gets into main, but that</span>&rsquo;<span>s</span>
<span>inefficient for most of the non-mission critical projects out there. A better approach is to</span>
<span>optimistically merge most changes as soon as not-rocket-science allows it, and then later review the</span>
<span>code in situ,  in the main branch. And instead of adding comments in web ui, just changing the code</span>
<span>in-place, sending a new PR ccing the original author.</span></p>

<figure class="blockquote">
<blockquote><ol start="14">
<li>
<span>Maintainers SHALL NOT make value judgments on correct patches.</span>
</li>
<li>
<span>Maintainers SHALL merge correct patches from other Contributors rapidly.</span>
</li>
</ol>
<p>&hellip;</p>
<ol start="18">
<li>
<span>Any Contributor who has value judgments on a patch SHOULD express these via their own patches.</span>
</li>
</ol>
</blockquote>
<figcaption><cite><a href="https://rfc.zeromq.org/spec/42/"><span>Collective Code Construction Contract</span></a></cite></figcaption>
</figure>
<p><span>I am skeptical that this exact workflow would</span>
<span>ever fly, but I am cautiously optimistic about </span><a href="https://zed.dev"><span>Zed</span>&rsquo;<span>s</span></a><span> idea about just allowing</span>
<span>two people to code in the same editor at the same time. I think that achieves a similar effect, and</span>
<span>nicely dodges unease about allowing temporarily unreviewed code.</span></p>
<p><span>Ok, back to git!</span></p>
<p><em><span>First</span></em><span>, not every project needs a clean history. Have you ever looked at the git history of your</span>
<span>personal blog or dotfiles? If you haven</span>&rsquo;<span>t, feel free to use a </span><code>.</code><span> as a commit message. I do that for</span>
<span class="display"><a href="https://github.com/matklad/matklad.github.io" class="url">https://github.com/matklad/matklad.github.io</a><span>,</span></span>
<span>it works fine so far.</span></p>
<p><em><span>Second</span></em><span>, not every change needs a great commit message. If a change is really minor, I would say</span>
<code>minor</code><span> is an okay commit message!</span></p>
<p><em><span>Third</span></em><span>, some changes absolutely do require very detailed commit messages. If there </span><em><span>is</span></em><span> a context,</span>
<span>by all means, include all of it into the commit message (and spill some as comments in the source</span>
<span>code). And here</span>&rsquo;<span>s a tip for this case: </span><em><span>write the commit message first!</span></em></p>
<p><span>When I work on a larger feature, I start with</span>
<code class="display">git commit --allow-empty</code>
<span>to type out what I set to do. Most of the time, by the third paragraph of the commit message I</span>
<span>realize that there</span>&rsquo;<span>s a flaw in my plan and refine it. So, by the time I get to actually writing the</span>
<span>code, I am already on the second iteration. And, when I am done, I just amend the commit with the</span>
<span>actual changes, and the commit message is already there, needing only minor adjustments.</span></p>
<p><span>And the last thing I want to touch about commit messages: </span><code>man git-commit</code><span> tells me that the summary</span>
<span>line should be shorter than 50 characters. This feels obviously wrong, that</span>&rsquo;<span>s much too short!</span>
<a href="https://www.kernel.org/doc/html/v4.10/process/submitting-patches.html"><span>Kernel docs</span></a><span> suggest a much</span>
<span>more reasonable 70-75 limit! And indeed, looking at a some recent kernel commits, 50 is clearly not</span>
<span>enough!</span></p>

<figure class="code-block">


<pre><code><span class="line">&lt;---               50 characters              ---&gt;</span>
<span class="line"></span>
<span class="line">get_maintainer: remove stray punctuation when cleaning file emails</span>
<span class="line">get_maintainer: correctly parse UTF-8 encoded names in files</span>
<span class="line">locking/osq_lock: Clarify osq_wait_next()</span>
<span class="line">locking/osq_lock: Clarify osq_wait_next() calling convention</span>
<span class="line">locking/osq_lock: Move the definition of optimistic_spin_node into osq_lock.c</span>
<span class="line">ftrace: Fix modification of direct_function hash while in use</span>
<span class="line">tracing: Fix blocked reader of snapshot buffer</span>
<span class="line">ring-buffer: Fix wake ups when buffer_percent is set to 100</span>
<span class="line">platform/x86/intel/pmc: Move GBE LTR ignore to suspend callback</span>
<span class="line">platform/x86/intel/pmc: Allow reenabling LTRs</span>
<span class="line">platform/x86/intel/pmc: Add suspend callback</span>
<span class="line">platform/x86: p2sb: Allow p2sb_bar() calls during PCI device probe</span>
<span class="line"></span>
<span class="line">&lt;---               50 characters              ---&gt;</span></code></pre>

</figure>
<p><span>Happy new year, dear reader!</span></p>
</section>
]]></content>
</entry>

</feed>
